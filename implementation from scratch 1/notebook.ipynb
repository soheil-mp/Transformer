{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<h1 style=\"text-align:center;\">Transformer</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### INITIAL SETUP\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-02 13:14:31.275079: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-02 13:14:31.276721: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-02 13:14:31.306841: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-02 13:14:31.307454: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-02 13:14:31.800207: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Import the libraries\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyperparameters\n",
    "\n",
    "# Hyperpararmeters for the model\n",
    "h = 8  # Number of self-attention heads\n",
    "d_k = 64  # Dimensionality of the linearly projected queries and keys\n",
    "d_v = 64  # Dimensionality of the linearly projected values\n",
    "d_model = 512  # Dimensionality of model layers' outputs\n",
    "d_ff = 2048  # Dimensionality of the inner fully connected layer\n",
    "n = 6  # Number of layers in the encoder stack\n",
    "\n",
    "# Hyperparameters for the training\n",
    "epochs = 20\n",
    "batch_size = 16\n",
    "beta_1 = 0.9\n",
    "beta_2 = 0.98\n",
    "epsilon = 1e-9\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### DATASET LOADER\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom class for the dataset\n",
    "class PrepareDataset:\n",
    "\n",
    "    # Constructor function\n",
    "    def __init__(self, **kwargs):\n",
    "\n",
    "        # Inherite the parent's constructor\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Initialization\n",
    "        self.n_sentences = 1_000     # Number of sentences in dataset\n",
    "        self.train_split = 0.8        # Train split ratio\n",
    "        self.val_split = 0.1          # Validation split ratio\n",
    "\n",
    "    # Function for creating and fitting a tokenizer to given dataset\n",
    "    def create_tokenizer(self, dataset):\n",
    "        \"\"\"\n",
    "        This function creates and fits a tokenizer to given dataset.\n",
    "\n",
    "        PARAMETERS\n",
    "        ===========================\n",
    "            - dataset (list): list of sentences\n",
    "\n",
    "        RETURNS\n",
    "        ===========================\n",
    "            - tokenizer (tensorflow tokenizer): fitted tokenizer\n",
    "        \"\"\"\n",
    "        \n",
    "        # Initialize a tokenizer\n",
    "        tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "\n",
    "        # Fit the tokenizer to the dataset\n",
    "        tokenizer.fit_on_texts(dataset)\n",
    "\n",
    "        return tokenizer\n",
    "    \n",
    "    # Function for finding the sequence length of the dataset\n",
    "    def find_sequence_length(self, dataset):\n",
    "        \"\"\"\n",
    "        This function finds the sequence length of the dataset.\n",
    "\n",
    "        PARAMETERS\n",
    "        ===========================\n",
    "            - dataset (list): list of sentences\n",
    "\n",
    "        RETURNS\n",
    "        ===========================\n",
    "            - sequence_length (int): sequence length of the dataset\n",
    "        \"\"\"\n",
    "\n",
    "        # Sequence length\n",
    "        sequence_length = max([len(i_seq.split()) for i_seq in dataset])\n",
    "\n",
    "        return sequence_length\n",
    "    \n",
    "    # Function for finding the vocabulary size\n",
    "    def find_vocabulary_size(self, tokenizer, dataset):\n",
    "        \"\"\"\n",
    "        This function finds the vocabulary size of the dataset.\n",
    "\n",
    "        PARAMETERS\n",
    "        ===========================\n",
    "            - tokenizer (tensorflow tokenizer): fitted tokenizer\n",
    "            - dataset (list): list of sentences\n",
    "\n",
    "        RETURNS\n",
    "        ===========================\n",
    "            - vocabulary_size (int): vocabulary size of the dataset\n",
    "        \"\"\"\n",
    "\n",
    "        # Fit the tokenizer to the dataset\n",
    "        tokenizer.fit_on_texts(dataset)\n",
    "\n",
    "        # Vocabulary size\n",
    "        vocabulary_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "        return vocabulary_size\n",
    "    \n",
    "    # Function for encoding and padding the input sequences\n",
    "    def encode_and_pad(self, dataset, tokenizer, sequence_length):\n",
    "        \"\"\"\n",
    "        This function encodes and pads the input sequences.\n",
    "\n",
    "        PARAMETERS\n",
    "        ===========================\n",
    "            - dataset (list): list of sentences\n",
    "            - tokenizer (tensorflow tokenizer): fitted tokenizer\n",
    "            - sequence_length (int): sequence length of the dataset\n",
    "\n",
    "        RETURNS\n",
    "        ===========================\n",
    "            - out (tensorflow tensor): encoded and padded dataset\n",
    "        \"\"\"\n",
    "\n",
    "        # Encode the dataset\n",
    "        encoded_dataset = tokenizer.texts_to_sequences(dataset)\n",
    "\n",
    "        # Pad the dataset\n",
    "        padded_dataset = tf.keras.preprocessing.sequence.pad_sequences(encoded_dataset, maxlen = sequence_length, padding = \"post\")\n",
    "\n",
    "        # Convert the dataset into tensor\n",
    "        out = tf.convert_to_tensor(padded_dataset, dtype=tf.int64)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    # Function for saving the tokenizer\n",
    "    def save_tokenizer(self, tokenizer, name):\n",
    "        \"\"\"\n",
    "        This function saves the tokenizer into a pickle file.\n",
    "\n",
    "        PARAMETERS\n",
    "        ===========================\n",
    "            - tokenizer (tensorflow tokenizer): fitted tokenizer\n",
    "            - name (str): name of the pickle file   \n",
    "\n",
    "        RETURNS \n",
    "        ===========================\n",
    "            - None\n",
    "        \"\"\"\n",
    "        # Open the pickle file\n",
    "        with open(name + \"_tokenizer.pkl\", \"wb\") as f:\n",
    "\n",
    "            # Dump the tokenizer\n",
    "            pickle.dump(tokenizer, f, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    # Call function\n",
    "    def __call__(self, filename, **kwargs):\n",
    "                 \n",
    "        # Load the dataset (already cleaned)\n",
    "        dataset_clean = pickle.load(open(filename, \"rb\"))\n",
    "\n",
    "        # Sample a subset of the dataset\n",
    "        dataset = dataset_clean[:self.n_sentences, :]\n",
    "\n",
    "        # Add the START and EOS tokens to each sentence\n",
    "        for i in range(dataset[:, 0].size):\n",
    "\n",
    "            # Add the tokens to the sentences \n",
    "            dataset[i, 0] = \"<START> \" + dataset[i, 0] + \" <EOS>\"\n",
    "            dataset[i, 1] = \"<START> \" + dataset[i, 1] + \" <EOS>\"\n",
    "\n",
    "        # Shuffle the dataset\n",
    "        np.random.shuffle(dataset)\n",
    "\n",
    "        # Split the dataset into train, val, test\n",
    "        train = dataset[:int(self.n_sentences * self.train_split)]\n",
    "        val   = dataset[int(self.n_sentences * self.train_split)  :  int(self.n_sentences * (1 - self.val_split))]\n",
    "        test  = dataset[int(self.n_sentences * (1 - self.val_split)) :]\n",
    "\n",
    "        # Tokenization process for encoder input\n",
    "        encoder_tokenizer       = self.create_tokenizer(dataset[:, 0])\n",
    "        encoder_sequence_length = self.find_sequence_length(dataset[:, 0])\n",
    "        encoder_vocabulary_size = self.find_vocabulary_size(encoder_tokenizer, train[:, 0])\n",
    "\n",
    "        # Tokenization process for decoder input\n",
    "        decoder_tokenizer       = self.create_tokenizer(dataset[:, 1])\n",
    "        decoder_sequence_length = self.find_sequence_length(dataset[:, 1])\n",
    "        decoder_vocabulary_size = self.find_vocabulary_size(decoder_tokenizer, train[:, 1])\n",
    "\n",
    "        # Encode and pad the train dataset\n",
    "        train_x = self.encode_and_pad(train[:, 0], encoder_tokenizer, encoder_sequence_length)\n",
    "        train_y = self.encode_and_pad(train[:, 1], decoder_tokenizer, decoder_sequence_length)\n",
    "\n",
    "        # Encode and pad the validation dataset\n",
    "        val_x = self.encode_and_pad(val[:, 0], encoder_tokenizer, encoder_sequence_length)\n",
    "        val_y = self.encode_and_pad(val[:, 1], decoder_tokenizer, decoder_sequence_length)\n",
    "\n",
    "        # Save the encoder/decoder tokenizer\n",
    "        self.save_tokenizer(encoder_tokenizer, \"./saved/encoder\")\n",
    "        self.save_tokenizer(decoder_tokenizer, \"./saved/decoder\")\n",
    "\n",
    "        # Save the testing dataset into a text file using savetxt\n",
    "        np.savetxt(\"./saved/test_dataset.txt\", test, fmt=\"%s\")\n",
    "\n",
    "        return (train_x, train_y, val_x, val_y, train, val, encoder_sequence_length, decoder_sequence_length, encoder_vocabulary_size, decoder_vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X shape:  (800, 7)\n",
      "Train Y shape:  (800, 9)\n",
      "Val X shape:  (100, 7)\n",
      "Val Y shape:  (100, 9)\n",
      "Train shape:  (800, 2)\n",
      "Val shape:  (100, 2)\n",
      "Encoder sequence length:  7\n",
      "Decoder sequence length:  9\n",
      "Encoder vocabulary size:  786\n",
      "Decoder vocabulary size:  1031\n",
      "Train X:  tf.Tensor(\n",
      "[[  1   6   4 ...   2   0   0]\n",
      " [  1  72  15 ...   0   0   0]\n",
      " [  1  30 317 ...   0   0   0]\n",
      " ...\n",
      " [  1  37 698 ...   0   0   0]\n",
      " [  1  14 699 ...  79   2   0]\n",
      " [  1  13   5 ...   2   0   0]], shape=(800, 7), dtype=int64)\n",
      "Train Y:  tf.Tensor(\n",
      "[[  1   4   5 ...   0   0   0]\n",
      " [  1  67  24 ...   0   0   0]\n",
      " [  1  92  74 ...   0   0   0]\n",
      " ...\n",
      " [  1  37   4 ...   0   0   0]\n",
      " [  1 876  16 ...   0   0   0]\n",
      " [  1  42   6 ...   0   0   0]], shape=(800, 9), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# Test out the codes\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Initialize the dataset class\n",
    "    dataset = PrepareDataset()\n",
    "\n",
    "    # Call it \n",
    "    train_x, train_y, val_x, val_y, train, val, encoder_sequence_length, decoder_sequence_length, encoder_vocabulary_size, decoder_vocabulary_size = dataset(\"./dataset/english-german-both.pkl\")\n",
    "\n",
    "    # Report\n",
    "    print(\"Train X shape: \", train_x.shape)\n",
    "    print(\"Train Y shape: \", train_y.shape)\n",
    "    print(\"Val X shape: \", val_x.shape)\n",
    "    print(\"Val Y shape: \", val_y.shape)\n",
    "    print(\"Train shape: \", train.shape)\n",
    "    print(\"Val shape: \", val.shape)\n",
    "    print(\"Encoder sequence length: \", encoder_sequence_length)\n",
    "    print(\"Decoder sequence length: \", decoder_sequence_length)\n",
    "    print(\"Encoder vocabulary size: \", encoder_vocabulary_size)\n",
    "    print(\"Decoder vocabulary size: \", decoder_vocabulary_size)\n",
    "    print(\"Train X: \", train_x)\n",
    "    print(\"Train Y: \", train_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### POSITIONAL ENCODING\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### POSITION EMBEDDING LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POsition embedding layer\n",
    "class PositionEmbeddingLayer(tf.keras.layers.Layer):\n",
    "\n",
    "    # Constructor function\n",
    "    def __init__(self, seq_length, vocab_size, output_dim, **kwargs):\n",
    "\n",
    "        # Inherite the parent's constructor\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Word embedding layer\n",
    "        self.word_embedding_layer = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=output_dim)\n",
    "\n",
    "        # Position embedding layer\n",
    "        self.position_embedding_layer = tf.keras.layers.Embedding(input_dim=seq_length, output_dim=output_dim)\n",
    "\n",
    "    # Call function\n",
    "    def call(self, inputs):\n",
    "\n",
    "        # Initialize the positions\n",
    "        position_indices = tf.range(start=0, limit=tf.shape(inputs)[-1])\n",
    "\n",
    "        # Feed words and positions to embedding layer\n",
    "        embedded_words     = self.word_embedding_layer(inputs)\n",
    "        embedded_positions = self.position_embedding_layer(position_indices)\n",
    "\n",
    "        # Sum up the embeddings\n",
    "        out = embedded_words + embedded_positions\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-02 14:33:08.486474: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [2,1]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from my_embedded_layer:  tf.Tensor(\n",
      "[[[ 1.6053319e-03 -8.3650574e-02 -6.1392568e-02 -3.3908986e-02\n",
      "   -1.9956470e-02 -7.1178794e-02]\n",
      "  [ 5.4670881e-02 -6.3885286e-02  3.7785515e-02 -1.1792352e-02\n",
      "    5.4344870e-02  3.0537870e-02]\n",
      "  [ 4.3200742e-02  6.0933828e-03  4.5772921e-03  5.1080152e-02\n",
      "   -2.7801074e-02  3.3011660e-04]\n",
      "  [ 1.2899458e-02 -2.4016820e-02 -6.1834540e-02  5.9015997e-02\n",
      "    5.4140411e-02  2.8231740e-03]\n",
      "  [ 4.3610688e-02 -1.3893481e-02 -9.2623115e-02 -7.5904988e-03\n",
      "    1.2955656e-02 -8.7610446e-03]]\n",
      "\n",
      " [[ 3.8222611e-02 -7.2161056e-02 -3.4222376e-02  8.4264893e-03\n",
      "    2.2202708e-02 -3.1928513e-02]\n",
      "  [-7.3291361e-05 -4.4291224e-02  1.8483829e-02  5.2194759e-02\n",
      "    3.5787903e-02 -2.3513233e-02]\n",
      "  [-3.7965227e-02  5.2355163e-02  2.6462451e-03  5.0589070e-02\n",
      "    7.0964545e-03 -9.1308467e-03]\n",
      "  [ 5.3874861e-02 -8.5730344e-02 -8.1827000e-02 -2.6694026e-02\n",
      "    7.5460486e-02  1.1989549e-02]\n",
      "  [ 4.3610688e-02 -1.3893481e-02 -9.2623115e-02 -7.5904988e-03\n",
      "    1.2955656e-02 -8.7610446e-03]]], shape=(2, 5, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# TEST THE CODE\n",
    "if __name__==\"__main__\":\n",
    "\n",
    "    # Hyperparameters\n",
    "    output_length = 6\n",
    "    output_sequence_length = 5\n",
    "    vocab_size = 10\n",
    "\n",
    "    # Sample text\n",
    "    sentences = [[\"I am a robot\"], [\"you too robot\"]]\n",
    "\n",
    "    # Convert to tf.data\n",
    "    sentence_data = tf.data.Dataset.from_tensor_slices(sentences)\n",
    "\n",
    "    # Convert all sentences to tensors\n",
    "    word_tensors = tf.convert_to_tensor(sentences, dtype=tf.string)\n",
    "    \n",
    "    # Vectorize the text\n",
    "    vectorize_layer = tf.keras.layers.TextVectorization(output_sequence_length=output_sequence_length, max_tokens=vocab_size)\n",
    "    vectorize_layer.adapt(sentence_data)\n",
    "    vectorized_words = vectorize_layer(word_tensors)\n",
    "\n",
    "    # Feed to the embedding layer\n",
    "    my_embedding_layer = PositionEmbeddingLayer(output_sequence_length, vocab_size, output_length)\n",
    "    embedded_layer_output = my_embedding_layer(vectorized_words)\n",
    "    \n",
    "    # Report\n",
    "    print(\"Output from my_embedded_layer: \", embedded_layer_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### POSITION EMBEDDING WITH FIXED WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional embedding layer class with initializing the weights with sine/cosine function\n",
    "class PositionEmbeddingLayerWithFixedWeights(tf.keras.layers.Layer):\n",
    "\n",
    "    # Constructor function\n",
    "    def __init__(self, seq_length, vocab_size, output_dim, **kwargs):\n",
    "\n",
    "        # Inherite parent's constructor\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Initialize the word / position embedding matrix (for initializing the weights with them)\n",
    "        word_embedding_matrix     = self.get_position_encoding(vocab_size, output_dim)\n",
    "        position_embedding_matrix = self.get_position_encoding(seq_length, output_dim)\n",
    "\n",
    "        # Initialize the word / position embedding layer\n",
    "        self.word_embedding_layer = tf.keras.layers.Embedding(input_dim=vocab_size, \n",
    "                                                              output_dim=output_dim,\n",
    "                                                              weights=[word_embedding_matrix],\n",
    "                                                              trainable=False)\n",
    "        self.position_embedding_layer = tf.keras.layers.Embedding(input_dim=seq_length,\n",
    "                                                                  output_dim=output_dim,\n",
    "                                                                  weights=[position_embedding_matrix],\n",
    "                                                                  trainable=False\n",
    "                                                                  )\n",
    "        \n",
    "    # Get position encoding (sine/cosine)\n",
    "    def get_position_encoding(self, seq_len, d, n=10_000):\n",
    "\n",
    "        # Initialize the positional matrix\n",
    "        P = np.zeros(shape=(seq_len, d))\n",
    "\n",
    "        # Loop over the range of sequence length\n",
    "        for k in range(seq_len):\n",
    "\n",
    "            # Loop over the index from 0 to d/2\n",
    "            for i in np.arange(0, int(d/2)):\n",
    "\n",
    "                # Denominator\n",
    "                denominator = np.power(n, 2*i/d)\n",
    "\n",
    "                # Sine\n",
    "                P[k, 2*i] = np.sin(k/denominator)\n",
    "\n",
    "                # Cosine\n",
    "                P[k, 2*i+1] = np.cos(k/denominator)\n",
    "\n",
    "        return P\n",
    "    \n",
    "    # Call function\n",
    "    def call(self, inputs):\n",
    "\n",
    "        # Initialize the position indices\n",
    "        position_indices = tf.range(start=0, limit=tf.shape(inputs)[-1])\n",
    "\n",
    "        # Feed the word and position data into the embedding layer\n",
    "        embedded_words = self.word_embedding_layer(inputs)\n",
    "        embedded_positions = self.position_embedding_layer(position_indices)\n",
    "\n",
    "        # Sum up the embedding layers\n",
    "        out = embedded_words + embedded_positions\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from my_embedded_layer:  tf.Tensor(\n",
      "[[[-0.9589243   1.2836622   0.23000172  1.9731903   0.01077196\n",
      "    1.9999421 ]\n",
      "  [ 0.56205547  1.5004725   0.3213085   1.9603932   0.01508068\n",
      "    1.9999142 ]\n",
      "  [ 1.566284    0.3377554   0.41192317  1.9433732   0.01938933\n",
      "    1.999877  ]\n",
      "  [ 1.0504174  -1.4061394   0.2314966   1.9860148   0.01077211\n",
      "    1.9999698 ]\n",
      "  [-0.7568025   0.3463564   0.18459873  1.982814    0.00861763\n",
      "    1.9999628 ]]\n",
      "\n",
      " [[ 0.14112     0.0100075   0.1387981   1.9903207   0.00646326\n",
      "    1.9999791 ]\n",
      "  [ 0.08466846 -0.11334133  0.23099795  1.9817369   0.01077207\n",
      "    1.9999605 ]\n",
      "  [ 1.8185948  -0.8322937   0.185397    1.9913884   0.00861771\n",
      "    1.9999814 ]\n",
      "  [ 0.14112     0.0100075   0.1387981   1.9903207   0.00646326\n",
      "    1.9999791 ]\n",
      "  [-0.7568025   0.3463564   0.18459873  1.982814    0.00861763\n",
      "    1.9999628 ]]], shape=(2, 5, 6), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-02 14:45:11.049058: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [2,1]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "# TEST THE CODE\n",
    "if __name__==\"__main__\":\n",
    "\n",
    "    # Hyperparameters\n",
    "    output_length = 6\n",
    "    output_sequence_length = 5\n",
    "    vocab_size = 10\n",
    "\n",
    "    # Sample text\n",
    "    sentences = [[\"I am a robot\"], [\"you too robot\"]]\n",
    "\n",
    "    # Convert to tf.data\n",
    "    sentence_data = tf.data.Dataset.from_tensor_slices(sentences)\n",
    "    \n",
    "    # Convert all sentences to tensors\n",
    "    word_tensors = tf.convert_to_tensor(sentences, dtype=tf.string)\n",
    "    \n",
    "    # Vectorize the text\n",
    "    vectorize_layer = tf.keras.layers.TextVectorization(output_sequence_length=output_sequence_length, max_tokens=vocab_size)\n",
    "    vectorize_layer.adapt(sentence_data)\n",
    "    vectorized_words = vectorize_layer(word_tensors)\n",
    "\n",
    "    # Feed to the embedding layer\n",
    "    attnisallyouneed_embedding = PositionEmbeddingLayerWithFixedWeights(output_sequence_length, vocab_size, output_length)\n",
    "    attnisallyouneed_output = attnisallyouneed_embedding(vectorized_words)\n",
    "    \n",
    "    # Report\n",
    "    print(\"Output from my_embedded_layer: \", attnisallyouneed_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### ATTENTION\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaled dot product attention class\n",
    "class ScaledDotProductAttentionLayer(tf.keras.layers.Layer):\n",
    "\n",
    "    # Constructor function\n",
    "    def __init__(self, **kwargs):\n",
    "\n",
    "        # Inherite the parent's constructor\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "\n",
    "    # Call function\n",
    "    def call(self, queries, keys, values, d_k, mask=None):\n",
    "\n",
    "        # Attention score\n",
    "        attention_score = tf.matmul(queries, keys, transpose_b=True) / tf.math.sqrt(tf.cast(d_k, tf.float32))\n",
    "\n",
    "        # Apply mask\n",
    "        if mask is not None:\n",
    "            attention_score += (-1e9 * mask)\n",
    "\n",
    "        # Apply softmax\n",
    "        weights = tf.keras.backend.softmax(attention_score)\n",
    "\n",
    "        # Calculate the weighted sum \n",
    "        out = tf.matmul(weights, values)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from the attention layer:  tf.Tensor(\n",
      "[[[0.574836   0.4910913  0.53175265 ... 0.60988843 0.31986004 0.81422716]\n",
      "  [0.54565096 0.5052882  0.5266657  ... 0.6169208  0.34833232 0.8172654 ]\n",
      "  [0.57250506 0.4821269  0.501388   ... 0.6195279  0.3234114  0.81893283]\n",
      "  [0.5697625  0.5005707  0.51635253 ... 0.6121317  0.32719454 0.81243914]\n",
      "  [0.5640133  0.4970683  0.5096431  ... 0.6160446  0.331049   0.8168155 ]]\n",
      "\n",
      " [[0.6667172  0.4838226  0.4819866  ... 0.35535455 0.30466646 0.5752652 ]\n",
      "  [0.66066664 0.4957752  0.46646112 ... 0.36564466 0.32325742 0.56742567]\n",
      "  [0.6644156  0.50229317 0.46419072 ... 0.36867    0.33093047 0.56911224]\n",
      "  [0.67318994 0.4788058  0.48524633 ... 0.34984627 0.31535807 0.579303  ]\n",
      "  [0.6668466  0.5082171  0.46986616 ... 0.37189427 0.3178724  0.5711498 ]]\n",
      "\n",
      " [[0.25559294 0.49669626 0.3333412  ... 0.5232684  0.7628709  0.5204613 ]\n",
      "  [0.25894582 0.49588963 0.33474487 ... 0.53464675 0.7557455  0.5351185 ]\n",
      "  [0.25962505 0.4757777  0.32071897 ... 0.5179433  0.76392955 0.5276534 ]\n",
      "  [0.25050327 0.50388426 0.36225963 ... 0.5228629  0.76226956 0.53109777]\n",
      "  [0.27220565 0.4611862  0.3277815  ... 0.51992244 0.7532843  0.5259638 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.3800796  0.6450296  0.5563331  ... 0.5493274  0.4446977  0.5632256 ]\n",
      "  [0.38994673 0.67548084 0.5416427  ... 0.49797812 0.48582593 0.5906564 ]\n",
      "  [0.3854489  0.6682986  0.5332027  ... 0.49474153 0.47926968 0.5920465 ]\n",
      "  [0.3961172  0.6855899  0.5630151  ... 0.5064274  0.4967868  0.5796167 ]\n",
      "  [0.39162883 0.6689789  0.5498191  ... 0.51377875 0.47903413 0.5829272 ]]\n",
      "\n",
      " [[0.74578375 0.46542105 0.43954447 ... 0.14720224 0.5706349  0.5945736 ]\n",
      "  [0.7582889  0.4574187  0.44807112 ... 0.15618941 0.5704733  0.5748816 ]\n",
      "  [0.75406915 0.45721495 0.44785604 ... 0.15098895 0.59197485 0.5859732 ]\n",
      "  [0.7647285  0.43677226 0.46228433 ... 0.14967637 0.56797355 0.5943461 ]\n",
      "  [0.76607    0.44129747 0.44962385 ... 0.15267026 0.574094   0.5741818 ]]\n",
      "\n",
      " [[0.5821521  0.33440655 0.57419664 ... 0.4483422  0.64243925 0.4291925 ]\n",
      "  [0.6059347  0.31399462 0.53315306 ... 0.48276478 0.66749257 0.44794944]\n",
      "  [0.602071   0.30949157 0.5391061  ... 0.47430483 0.65656567 0.4526846 ]\n",
      "  [0.6054553  0.32850763 0.53847766 ... 0.48676616 0.6768953  0.44237736]\n",
      "  [0.5969315  0.31413388 0.54417694 ... 0.47190654 0.6553165  0.43833396]]], shape=(64, 5, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# TEST THE CODE\n",
    "if __name__==\"__main__\":\n",
    "\n",
    "    # Hyperparameters\n",
    "    input_seq_length = 5    # Maximum length of the input sequence\n",
    "    d_k = 64                # Dimensionality of the linearly projected queries and keys\n",
    "    d_v = 64                # Dimensionality of the linearly projected values\n",
    "    batch_size = 64         # Batch size from the training process\n",
    "\n",
    "    # Initialize the queries, keys, values randomely\n",
    "    queries = np.random.random((batch_size, input_seq_length, d_k))\n",
    "    keys    = np.random.random((batch_size, input_seq_length, d_k))\n",
    "    values  = np.random.random((batch_size, input_seq_length, d_v))\n",
    "\n",
    "    # Feed to the attention layer\n",
    "    attention = ScaledDotProductAttentionLayer()\n",
    "    out = attention(queries, keys, values, d_k)\n",
    "\n",
    "    # Report\n",
    "    print(\"Output from the attention layer: \", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-head attention class\n",
    "class MultiHeadAttentionLayer(tf.keras.layers.Layer):\n",
    "\n",
    "    # Constructor function\n",
    "    def __init__(self, h, d_k, d_v, d_model, **kwargs):\n",
    "\n",
    "        # Inherite the parent's constructor\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Initialize the scaled dot product attention layer\n",
    "        self.attention = ScaledDotProductAttentionLayer()\n",
    "\n",
    "        # Initialization\n",
    "        self.heads = h            # Number of attention heads\n",
    "        self.d_k = d_k            # Dimension of the key vector (and also the query vector)\n",
    "        self.d_v = d_v            # Dimension of the value vector\n",
    "        self.d_model = d_model    # Dimension of the model\n",
    "\n",
    "        # Initialize dense layer for learned projection matrix for queries, keys, values, and model\n",
    "        self.W_q = tf.keras.layers.Dense(units=d_k)\n",
    "        self.W_k = tf.keras.layers.Dense(units=d_k)\n",
    "        self.W_v = tf.keras.layers.Dense(units=d_v)\n",
    "        self.W_o = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "\n",
    "    # Function for reshaping the tensor \n",
    "    def reshape_tensor(self, x, heads, flag):\n",
    "\n",
    "        # If flag is on\n",
    "        # Used when recieving the linearly projected queries, keys, or values as input\n",
    "        # Final shape should be: (batch_size, heads, seq_length, -1)\n",
    "        if flag:\n",
    "\n",
    "            # Reshape the tensor\n",
    "            x = tf.reshape(x, shape=(tf.shape(x)[0], tf.shape(x)[1], heads, -1))\n",
    "\n",
    "            # Transpose the tensor\n",
    "            x = tf.transpose(x, perm=(0, 2, 1, 3))\n",
    "\n",
    "        # If flag is off\n",
    "        # Use after the data feeded into the multi head attention layer\n",
    "        # Final shape should be: (batch_size, seq_length, d_k)\n",
    "        else:\n",
    "\n",
    "            # Transpose\n",
    "            x = tf.transpose(x, perm=(0, 2, 1, 3))\n",
    "\n",
    "            # Reshape\n",
    "            x = tf.reshape(x, shape=(tf.shape(x)[0], tf.shape(x)[1], self.d_k))\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "    # Call function\n",
    "    def call(self, queries, keys, values, mask=None):\n",
    "\n",
    "        # Reshape queries, keys, values to be able to compute all heads in parallel\n",
    "        queries_reshaped = self.reshape_tensor(self.W_q(queries), self.heads, True)\n",
    "        keys_reshaped = self.reshape_tensor(self.W_k(keys), self.heads, True)\n",
    "        values_reshaped = self.reshape_tensor(self.W_v(values), self.heads, True)\n",
    "        \n",
    "        # Compute multi-head attention\n",
    "        output_reshaped = self.attention(queries_reshaped, keys_reshaped, values_reshaped, self.d_k, mask)\n",
    "\n",
    "        # Rearrange the output into concatenated form\n",
    "        output = self.reshape_tensor(output_reshaped, self.heads, False)\n",
    "\n",
    "        # Apply the linear projection to the output\n",
    "        output = self.W_o(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from the multi-head attention layer:  tf.Tensor(\n",
      "[[[ 0.0956052   0.0368684  -0.06244076 ... -0.49866214  0.02797615\n",
      "    0.23295166]\n",
      "  [ 0.09812158  0.03652298 -0.05997851 ... -0.501119    0.02957674\n",
      "    0.2343919 ]\n",
      "  [ 0.09838251  0.03684737 -0.05993587 ... -0.49918228  0.02806355\n",
      "    0.23281895]\n",
      "  [ 0.096177    0.03611504 -0.0607796  ... -0.49894232  0.02779351\n",
      "    0.23206094]\n",
      "  [ 0.09780447  0.03639729 -0.06134978 ... -0.5007972   0.02788131\n",
      "    0.23520443]]\n",
      "\n",
      " [[ 0.13159178 -0.03802197 -0.07355646 ... -0.45416084 -0.06452292\n",
      "    0.3736113 ]\n",
      "  [ 0.12945977 -0.03787013 -0.07733262 ... -0.453199   -0.06621869\n",
      "    0.37587428]\n",
      "  [ 0.13113408 -0.04006882 -0.0755689  ... -0.45466846 -0.06252465\n",
      "    0.37526393]\n",
      "  [ 0.12822443 -0.04119419 -0.07878751 ... -0.45280933 -0.06361929\n",
      "    0.37526923]\n",
      "  [ 0.13056709 -0.03751043 -0.07559039 ... -0.45715246 -0.06496883\n",
      "    0.37399   ]]\n",
      "\n",
      " [[ 0.13514951 -0.01404922 -0.12015079 ... -0.44921258 -0.09544843\n",
      "    0.4220631 ]\n",
      "  [ 0.13238913 -0.01498937 -0.12097348 ... -0.45429668 -0.09535277\n",
      "    0.4183391 ]\n",
      "  [ 0.13473101 -0.01602756 -0.1193428  ... -0.44687793 -0.09591092\n",
      "    0.42320845]\n",
      "  [ 0.1336272  -0.01406965 -0.11945157 ... -0.44955078 -0.09557678\n",
      "    0.42409286]\n",
      "  [ 0.13419527 -0.01470209 -0.11969148 ... -0.4503614  -0.09616727\n",
      "    0.4206381 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.16857964 -0.06863531 -0.19282241 ... -0.44260785 -0.05373504\n",
      "    0.23516344]\n",
      "  [ 0.17103244 -0.07006608 -0.19608393 ... -0.4413581  -0.05479174\n",
      "    0.23671004]\n",
      "  [ 0.16441505 -0.07157442 -0.1912503  ... -0.4447796  -0.05197924\n",
      "    0.23388462]\n",
      "  [ 0.16554922 -0.06912325 -0.1942615  ... -0.44255504 -0.05259119\n",
      "    0.23581387]\n",
      "  [ 0.16474481 -0.07124279 -0.19209355 ... -0.44422275 -0.05252396\n",
      "    0.23532791]]\n",
      "\n",
      " [[ 0.26101422 -0.07421907 -0.14668174 ... -0.4579319  -0.03324161\n",
      "    0.3091056 ]\n",
      "  [ 0.25637126 -0.06782303 -0.1463339  ... -0.45928603 -0.03281856\n",
      "    0.3039919 ]\n",
      "  [ 0.25379944 -0.06987381 -0.14484066 ... -0.45991993 -0.03388688\n",
      "    0.3029876 ]\n",
      "  [ 0.26097432 -0.07324246 -0.14766489 ... -0.45736733 -0.03195737\n",
      "    0.30623275]\n",
      "  [ 0.25759223 -0.07007186 -0.14523195 ... -0.45941207 -0.0307522\n",
      "    0.30743307]]\n",
      "\n",
      " [[ 0.14183253 -0.06971387 -0.21041438 ... -0.40785027 -0.08951876\n",
      "    0.34630194]\n",
      "  [ 0.14434515 -0.07151521 -0.20495397 ... -0.40559894 -0.08939689\n",
      "    0.34284973]\n",
      "  [ 0.14316176 -0.07427406 -0.20673397 ... -0.41113365 -0.09211552\n",
      "    0.34182474]\n",
      "  [ 0.14510885 -0.07193033 -0.20604943 ... -0.40925932 -0.09286863\n",
      "    0.3401705 ]\n",
      "  [ 0.14289103 -0.07133355 -0.20692436 ... -0.41106123 -0.08805124\n",
      "    0.34294495]]], shape=(64, 5, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# TEST THE CODE\n",
    "if __name__==\"__main__\":\n",
    "\n",
    "    # Hyperparameters\n",
    "    input_seq_length = 5    # Maximum length of the input sequence\n",
    "    h = 8                   # Number of self-attention heads\n",
    "    d_k = 64                # Dimensionality of the linearly projected queries and keys\n",
    "    d_v = 64                # Dimensionality of the linearly projected values\n",
    "    d_model = 512           # Dimensionality of the model sub-layers' outputs\n",
    "    batch_size = 64         # Batch size from the training process\n",
    "\n",
    "    # Initialize the queries, keys, values randomely\n",
    "    queries = np.random.random((batch_size, input_seq_length, d_k))\n",
    "    keys    = np.random.random((batch_size, input_seq_length, d_k))\n",
    "    values  = np.random.random((batch_size, input_seq_length, d_v))\n",
    "\n",
    "    # Feed to the multi-head attention layer\n",
    "    multihead_attention = MultiHeadAttentionLayer(h, d_k, d_v, d_model)\n",
    "    out = multihead_attention(queries, keys, values)\n",
    "\n",
    "    # Report\n",
    "    print(\"Output from the multi-head attention layer: \", out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### MASKING\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for masking the paddings\n",
    "def padding_mask(inputs):\n",
    "\n",
    "    # Create mask (i.e. marks zero paddings by a 1 and 0 elsewhere)\n",
    "    mask = tf.math.equal(inputs, 0)\n",
    "    mask = tf.cast(mask, tf.float32)\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for lookahead mask\n",
    "def lookahead_mask(shape):\n",
    "\n",
    "    # Create mask (i.e. marks future enteries by a 1 and 0 elsewhere)\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((shape, shape)), num_lower=-1, num_upper=0)\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:  [1 2 3 4 0 0 0]\n",
      "Masked inputs:  tf.Tensor([0. 0. 0. 0. 1. 1. 1.], shape=(7,), dtype=float32)\n",
      "Masked lookahead of shape 5:  tf.Tensor(\n",
      "[[0. 1. 1. 1. 1.]\n",
      " [0. 0. 1. 1. 1.]\n",
      " [0. 0. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0.]], shape=(5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# TEST THE CODE\n",
    "if __name__==\"__main__\":\n",
    "\n",
    "    # Sample dataset\n",
    "    inputs = np.array([1, 2, 3, 4, 0, 0, 0])\n",
    "    \n",
    "    # Apply padding mask\n",
    "    masked_inputs = padding_mask(inputs)\n",
    "    \n",
    "    # Apply lookahead mask\n",
    "    masked_lookahead = lookahead_mask(shape=5)\n",
    "\n",
    "    # Report\n",
    "    print(\"Inputs: \", inputs)\n",
    "    print(\"Masked inputs: \", masked_inputs)\n",
    "    print(\"Masked lookahead of shape 5: \", masked_lookahead)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### ENCODER\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: START HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom layer for Add & Norm layer\n",
    "class AddNormalizationLayer(tf.keras.layers.Layer):\n",
    "\n",
    "    # Constructor function\n",
    "    def __init__(self, **kwargs):\n",
    "\n",
    "        # Inherite the parent's constructor\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Initialize the layer normalization layer\n",
    "        self.layer_norm = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    # Call function\n",
    "    def call(self, x, sublayer_x):\n",
    "\n",
    "        # Add the sublayer input and output together\n",
    "        add = x + sublayer_x\n",
    "\n",
    "        # Apply layer normalization\n",
    "        out = self.layer_norm(add)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom layer for Feed-Forward layer\n",
    "class FeedForwardLayer(tf.keras.layers.Layer):\n",
    "\n",
    "    # Constructor function\n",
    "    def __init__(self, d_ff, d_model, **kwargs):\n",
    "\n",
    "        # Inherite the parent's constructor\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Initialize the dense layers\n",
    "        self.fully_connected_1 = tf.keras.layers.Dense(units=d_ff)\n",
    "        self.fully_connected_2 = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        # Initialize the activation function\n",
    "        self.activation = tf.keras.layers.ReLU()\n",
    "\n",
    "    # Call function\n",
    "    def call(self, x):\n",
    "\n",
    "        # Feed the data\n",
    "        x = self.fully_connected_1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.fully_connected_2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom layer for Transformer Encoder\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "\n",
    "    # Constructor function\n",
    "    def __init__(self, sequence_length, h, d_k, d_v, d_model, d_ff, rate, **kwargs):\n",
    "\n",
    "        # Inherite the parent's constructor\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Initialization (to use in rest of the class)\n",
    "        self.sequence_length = sequence_length \n",
    "        self.d_model = d_model\n",
    "\n",
    "        # Attention layer\n",
    "        self.multihead_attention = MultiHeadAttentionLayer(h, d_k, d_v, d_model)\n",
    "\n",
    "        # Feed-forward layer\n",
    "        self.feed_forward = FeedForwardLayer(d_ff, d_model)\n",
    "\n",
    "        # Add & Norm layer\n",
    "        self.add_norm_1 = AddNormalizationLayer()\n",
    "        self.add_norm_2 = AddNormalizationLayer()\n",
    "\n",
    "        # Dropout layer\n",
    "        self.dropout_1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout_2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "        # Build the model\n",
    "        self.build(input_shape=[None, sequence_length, d_model])\n",
    "\n",
    "    # Build function\n",
    "    def build_graph(self):\n",
    "\n",
    "        # Construct the model\n",
    "        input_layer = tf.keras.layers.Input(shape=(self.sequence_length, self.d_model))\n",
    "        return tf.keras.Model(inputs=[input_layer], outputs=self.call(input_layer, None, True))\n",
    "\n",
    "    # Call function\n",
    "    def call(self, x, padding_mask, training):\n",
    "\n",
    "        # Feed the data\n",
    "        multihead_output   = self.multihead_attention(x, x, x, padding_mask)\n",
    "        multihead_output   = self.dropout_1(multihead_output, training=training)\n",
    "        addnorm_output     = self.add_norm_1(x, multihead_output)\n",
    "        feedforward_output = self.feed_forward(addnorm_output)\n",
    "        feedforward_output = self.dropout_2(feedforward_output, training=training)\n",
    "        addnorm_output     = self.add_norm_2(addnorm_output, feedforward_output)\n",
    "\n",
    "        return addnorm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom layer for the full model\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "\n",
    "    # Constructor function\n",
    "    def __init__(self, vocab_size, sequence_length, h, d_k, d_v, d_model, d_ff, n, rate, **kwargs):\n",
    "\n",
    "        # Inherite the parent's constructor\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Positional encoding layer\n",
    "        self.positional_encoding = PositionEmbeddingLayerWithFixedWeights(sequence_length, vocab_size, d_model)\n",
    "\n",
    "        # Dropout layer\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "        # Encoder layers (for N times)\n",
    "        self.encoder_layer = [EncoderLayer(sequence_length, h, d_k, d_v, d_model, d_ff, rate) for _ in range(n)]\n",
    "\n",
    "    # Call function\n",
    "    def call(self, input_sentence, padding_mask, training):\n",
    "\n",
    "        # Feed the data\n",
    "        x = self.positional_encoding(input_sentence)\n",
    "        x = self.dropout(x, training=training) \n",
    "        for i_index, i_layer in enumerate(self.encoder_layer):\n",
    "            x = i_layer(x, padding_mask, training)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 64, 512)]    0           []                               \n",
      "                                                                                                  \n",
      " multi_head_attention_layer_7 (  (None, 64, 512)     131776      ['input_1[0][0]',                \n",
      " MultiHeadAttentionLayer)                                         'input_1[0][0]',                \n",
      "                                                                  'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 64, 512)      0           ['multi_head_attention_layer_7[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " add_normalization_layer_12 (Ad  (None, 64, 512)     1024        ['input_1[0][0]',                \n",
      " dNormalizationLayer)                                             'dropout_13[0][0]']             \n",
      "                                                                                                  \n",
      " feed_forward_layer_6 (FeedForw  (None, 64, 512)     2099712     ['add_normalization_layer_12[0][0\n",
      " ardLayer)                                                       ]']                              \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 64, 512)      0           ['feed_forward_layer_6[0][0]']   \n",
      "                                                                                                  \n",
      " add_normalization_layer_13 (Ad  (None, 64, 512)     1024        ['add_normalization_layer_12[0][0\n",
      " dNormalizationLayer)                                            ]',                              \n",
      "                                                                  'dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,233,536\n",
      "Trainable params: 2,233,536\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model summary:  None\n",
      "Output of the encoder: \n",
      " tf.Tensor(\n",
      "[[[-5.16268611e-01 -2.07339191e+00 -7.36966789e-01 ... -8.91976058e-01\n",
      "   -5.24424374e-01 -1.04247320e+00]\n",
      "  [ 3.15607071e-01 -3.68786037e-01  1.12322066e-02 ... -2.06671071e+00\n",
      "    3.35365176e-01 -1.46602666e+00]\n",
      "  [-3.59878033e-01 -1.24792290e+00 -6.47945881e-01 ... -1.11123502e+00\n",
      "    2.37852007e-01 -1.25086820e+00]\n",
      "  ...\n",
      "  [-9.34009969e-01 -1.26245999e+00  3.86977375e-01 ... -5.57576478e-01\n",
      "    1.02224290e+00 -2.27751064e+00]\n",
      "  [-6.13676012e-01 -1.81363332e+00 -1.42289922e-01 ... -6.83086276e-01\n",
      "   -5.49545407e-01 -1.59324074e+00]\n",
      "  [-4.19902474e-01 -1.81564212e+00  1.45779282e-01 ... -4.74734664e-01\n",
      "   -6.32748842e-01 -1.50671434e+00]]\n",
      "\n",
      " [[-3.36579382e-01 -1.31395733e+00 -4.84735578e-01 ... -8.19327295e-01\n",
      "    6.08321369e-01 -8.60648811e-01]\n",
      "  [-5.02787530e-01 -8.85323226e-01 -8.90458822e-01 ... -1.42770219e+00\n",
      "    2.24376500e-01 -2.26452494e+00]\n",
      "  [-4.77479815e-01 -1.31027627e+00 -5.85805774e-01 ... -9.96663809e-01\n",
      "    3.22651833e-01 -1.48731315e+00]\n",
      "  ...\n",
      "  [-2.92024016e-01 -1.66344285e+00  8.41854632e-01 ... -1.01593769e+00\n",
      "   -4.48440015e-02 -1.95435107e+00]\n",
      "  [-2.91668773e-01 -1.00219691e+00  2.30525047e-01 ... -2.59544551e-01\n",
      "    3.45443994e-01 -1.93767118e+00]\n",
      "  [-1.40381500e-01 -1.32386065e+00  4.95766491e-01 ... -7.11124778e-01\n",
      "    2.60968003e-02 -1.47838557e+00]]\n",
      "\n",
      " [[-2.28527486e-01 -4.87615258e-01  2.22667381e-01 ... -1.49334013e+00\n",
      "   -1.53198212e-01 -1.92179978e+00]\n",
      "  [ 1.32673625e-02 -1.07687807e+00 -1.38139591e-01 ... -1.51945090e+00\n",
      "   -4.84757781e-01 -1.67562199e+00]\n",
      "  [-5.08857787e-01 -1.68468297e+00 -9.15660858e-02 ... -1.21505272e+00\n",
      "    1.22812986e-02 -1.63153148e+00]\n",
      "  ...\n",
      "  [-3.57779175e-01 -5.91276407e-01 -4.08837855e-01 ... -2.09756517e+00\n",
      "    3.91693324e-01 -1.62651944e+00]\n",
      "  [-2.20903214e-02 -1.66411102e+00  2.12063968e-01 ... -1.57217574e+00\n",
      "   -6.20369792e-01 -2.06406093e+00]\n",
      "  [-9.36160237e-02 -1.68530893e+00 -7.13080704e-01 ... -1.28445709e+00\n",
      "   -2.44768448e-02 -1.74283040e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-5.01702428e-01 -1.18983138e+00  3.23093049e-02 ... -1.11394656e+00\n",
      "    1.53841868e-01 -1.31412852e+00]\n",
      "  [ 3.29908013e-01 -6.71568573e-01  3.35228369e-02 ... -1.54796493e+00\n",
      "   -3.77128869e-01 -1.31729805e+00]\n",
      "  [-1.93046182e-01 -1.32296610e+00  2.69329045e-02 ... -1.70105493e+00\n",
      "   -2.88512558e-01 -1.75785804e+00]\n",
      "  ...\n",
      "  [-3.80496889e-01 -1.64583063e+00 -6.78591803e-02 ... -9.77342844e-01\n",
      "    5.71848512e-01 -1.78870213e+00]\n",
      "  [-9.04252768e-01 -1.66680205e+00  1.68121889e-01 ... -5.59328139e-01\n",
      "    4.05407429e-01 -1.81366789e+00]\n",
      "  [-7.03136563e-01 -7.78340340e-01  4.40177172e-01 ... -1.10432982e+00\n",
      "   -5.55857420e-01 -2.02930570e+00]]\n",
      "\n",
      " [[-6.28208041e-01 -9.36411142e-01  2.32228972e-02 ... -9.19209898e-01\n",
      "    6.64152443e-01 -1.30111754e+00]\n",
      "  [-6.46290720e-01 -1.61762929e+00 -1.57579035e-03 ... -5.56964755e-01\n",
      "   -1.03895843e-01 -1.55606639e+00]\n",
      "  [-3.92328233e-01 -7.09078193e-01 -1.49303935e-02 ... -6.63408816e-01\n",
      "   -8.27987969e-01 -1.54370034e+00]\n",
      "  ...\n",
      "  [-2.00565755e-01 -1.89062190e+00  6.72422290e-01 ... -6.43643320e-01\n",
      "   -7.77873769e-02 -1.33817041e+00]\n",
      "  [-6.54141247e-01 -8.03473830e-01  1.44906032e+00 ... -7.84292638e-01\n",
      "   -5.01219556e-02 -1.70448887e+00]\n",
      "  [-4.23553288e-02 -1.07420945e+00  2.43365765e-01 ...  7.73871019e-02\n",
      "   -2.34671205e-01 -1.24829209e+00]]\n",
      "\n",
      " [[-5.65242648e-01 -1.15891635e+00 -2.39205927e-01 ... -1.51171339e+00\n",
      "    2.42721438e-01 -1.63659775e+00]\n",
      "  [ 1.92779019e-01 -1.32858169e+00 -2.09639564e-01 ... -1.26667380e+00\n",
      "    5.68953097e-01 -1.42926371e+00]\n",
      "  [-1.80516928e-01 -1.51717925e+00  1.23032480e-01 ... -1.30641627e+00\n",
      "    2.18753695e-01 -1.43787336e+00]\n",
      "  ...\n",
      "  [-3.81535262e-01 -2.07063031e+00  7.39550471e-01 ... -2.42019728e-01\n",
      "   -5.47149181e-01 -1.56886351e+00]\n",
      "  [-7.35863149e-01 -1.54297781e+00  1.72318920e-01 ... -8.23113620e-01\n",
      "   -2.83761974e-02 -1.22627068e+00]\n",
      "  [-7.41695017e-02 -1.41637266e+00  3.35872531e-01 ... -3.25102359e-01\n",
      "   -2.84407884e-01 -1.65291166e+00]]], shape=(64, 64, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# TEST THE CODE\n",
    "if __name__==\"__main__\":\n",
    "\n",
    "    # Hyperparameters\n",
    "    h = 8                     # Number of self-attention heads\n",
    "    d_k = 64                  # Dimension of the key and query vectors\n",
    "    d_v = 64                  # Dimension of the value vectors\n",
    "    d_ff = 2048               # Dimension of the inner feed-forward layer\n",
    "    d_model = 512             # Dimension of the mode syb-layer' output\n",
    "    n = 6                     # Number of encoder layers\n",
    "    batch_size = 64           # Batch size\n",
    "    dropout_rate = 0.1        # Dropout rate\n",
    "    enc_vocab_size = 8192     # Encoder vocabulary size\n",
    "    input_seq_length = 64     # Maximum length of the input sequence\n",
    "\n",
    "    # Sample input dataset\n",
    "    input_seq = np.random.random((batch_size, input_seq_length))\n",
    "\n",
    "    # Feed to the encoder\n",
    "    encoder = Encoder(enc_vocab_size, input_seq_length, h, d_k, d_v, d_model, d_ff, n, dropout_rate)\n",
    "    output_encoder = encoder(input_seq, None, True)\n",
    "    \n",
    "    # Model summary\n",
    "    encoder_layer = EncoderLayer(input_seq_length, h, d_k, d_v, d_model, d_ff, dropout_rate)\n",
    "    \n",
    "    # Report\n",
    "    print(\"Model summary: \", encoder_layer.build_graph().summary())\n",
    "    print(\"Output of the encoder: \\n\", output_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### DECODER\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom layer for decoder layer\n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "\n",
    "    # Constructor function\n",
    "    def __init__(self, sequence_length, h, d_k, d_v, d_model, d_ff, rate, **kwargs):\n",
    "\n",
    "        # Inherite parent's constructor\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Multi-head attention layer\n",
    "        self.multihead_attention_1 = MultiHeadAttentionLayer(h, d_k, d_v, d_model)\n",
    "        self.multihead_attention_2 = MultiHeadAttentionLayer(h, d_k, d_v, d_model)\n",
    "\n",
    "        # Feed-forward layer\n",
    "        self.feed_forward = FeedForwardLayer(d_ff, d_model)\n",
    "\n",
    "        # Add & Norm layer\n",
    "        self.add_norm_1 = AddNormalizationLayer()\n",
    "        self.add_norm_2 = AddNormalizationLayer()\n",
    "        self.add_norm_3 = AddNormalizationLayer()\n",
    "\n",
    "        # Dropout layer\n",
    "        self.dropout_1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout_2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout_3 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "        # Initialization\n",
    "        self.sequence_length = sequence_length\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # Build the model\n",
    "        self.build(input_shape=[None, sequence_length, d_model])\n",
    "\n",
    "    # Build function\n",
    "    def build_graph(self):\n",
    "\n",
    "        # Construct the model\n",
    "        input_layer = tf.keras.layers.Input(shape=(self.sequence_length, self.d_model))\n",
    "        return tf.keras.Model(inputs=[input_layer], outputs=self.call(input_layer, input_layer, None, None, True))\n",
    "\n",
    "    # Call function\n",
    "    def call(self, x, encoder_output, lookahead_mask, padding_mask, training):\n",
    "\n",
    "        # Feed the data\n",
    "        multihead_output_1 = self.multihead_attention_1(x, x, x, lookahead_mask)\n",
    "        multihead_output_1 = self.dropout_1(multihead_output_1, training=training)\n",
    "        addnorm_output_1 = self.add_norm_1(x, multihead_output_1)\n",
    "\n",
    "        multihead_output_2 = self.multihead_attention_2(addnorm_output_1, encoder_output, encoder_output, padding_mask)\n",
    "        multihead_output_2 = self.dropout_2(multihead_output_2, training=training)\n",
    "        addnorm_output_2 = self.add_norm_2(addnorm_output_1, multihead_output_2)\n",
    "\n",
    "        feedforward_output = self.feed_forward(addnorm_output_2)\n",
    "        feedforward_output = self.dropout_3(feedforward_output, training=training)\n",
    "        addnorm_output_3 = self.add_norm_3(addnorm_output_2, feedforward_output)\n",
    "\n",
    "        return addnorm_output_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom layer for the full decoder model\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "\n",
    "    # Constructor function\n",
    "    def __init__(self, vocab_size, sequence_length, h, d_k, d_v, d_model, d_ff, n, rate, **kwargs):\n",
    "\n",
    "        # Inherite the parent's constructor\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Positional encoding layer\n",
    "        self.pos_encoding = PositionEmbeddingLayerWithFixedWeights(sequence_length, vocab_size, d_model)\n",
    "\n",
    "        # Dropout layer\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "        # Decoder layers (for N times)\n",
    "        self.decoder_layer = [DecoderLayer(sequence_length, h, d_k, d_v, d_model, d_ff, rate) for _ in range(n)]\n",
    "\n",
    "    # Call function\n",
    "    def call(self, output_target, encoder_output, lookahead_mask, padding_mask, training):\n",
    "\n",
    "        # Feed the data\n",
    "        x = self.pos_encoding(output_target)\n",
    "        x = self.dropout(x, training=training)\n",
    "        for i_index, i_layer in enumerate(self.decoder_layer):\n",
    "            x = i_layer(x, encoder_output, lookahead_mask, padding_mask, training)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 40, 512)]    0           []                               \n",
      "                                                                                                  \n",
      " multi_head_attention_layer_20   (None, 40, 512)     131776      ['input_2[0][0]',                \n",
      " (MultiHeadAttentionLayer)                                        'input_2[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_34 (Dropout)           (None, 40, 512)      0           ['multi_head_attention_layer_20[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " add_normalization_layer_32 (Ad  (None, 40, 512)     1024        ['input_2[0][0]',                \n",
      " dNormalizationLayer)                                             'dropout_34[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_layer_21   (None, 40, 512)     131776      ['add_normalization_layer_32[0][0\n",
      " (MultiHeadAttentionLayer)                                       ]',                              \n",
      "                                                                  'input_2[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_35 (Dropout)           (None, 40, 512)      0           ['multi_head_attention_layer_21[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " add_normalization_layer_33 (Ad  (None, 40, 512)     1024        ['add_normalization_layer_32[0][0\n",
      " dNormalizationLayer)                                            ]',                              \n",
      "                                                                  'dropout_35[0][0]']             \n",
      "                                                                                                  \n",
      " feed_forward_layer_13 (FeedFor  (None, 40, 512)     2099712     ['add_normalization_layer_33[0][0\n",
      " wardLayer)                                                      ]']                              \n",
      "                                                                                                  \n",
      " dropout_36 (Dropout)           (None, 40, 512)      0           ['feed_forward_layer_13[0][0]']  \n",
      "                                                                                                  \n",
      " add_normalization_layer_34 (Ad  (None, 40, 512)     1024        ['add_normalization_layer_33[0][0\n",
      " dNormalizationLayer)                                            ]',                              \n",
      "                                                                  'dropout_36[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,366,336\n",
      "Trainable params: 2,366,336\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model summary:  None\n",
      "Decoder Output:  tf.Tensor(\n",
      "[[[-1.5292352   0.8729291  -0.02152485 ...  0.78501666 -0.51788604\n",
      "    1.1951222 ]\n",
      "  [-1.5196913   0.81038725  0.15513662 ...  0.8263404  -0.6179581\n",
      "    1.1437477 ]\n",
      "  [-1.5722016   0.66756904  0.24335258 ...  0.8533807  -0.65395087\n",
      "    1.1021852 ]\n",
      "  ...\n",
      "  [-1.3818479   0.8869137  -0.17170301 ...  0.90332425 -0.7892979\n",
      "    1.1712018 ]\n",
      "  [-1.2814636   0.8806526  -0.13349947 ...  0.90269536 -0.8317453\n",
      "    1.244688  ]\n",
      "  [-1.2498192   0.72872066  0.04493522 ...  0.9419766  -0.8288834\n",
      "    1.2391227 ]]\n",
      "\n",
      " [[-1.4630816   0.8954198  -0.16320816 ...  0.84234357 -0.5520041\n",
      "    1.1335145 ]\n",
      "  [-1.4522104   0.83709276  0.00677852 ...  0.8773391  -0.6435093\n",
      "    1.093471  ]\n",
      "  [-1.5006398   0.6976769   0.09070726 ...  0.90596086 -0.69336027\n",
      "    1.055528  ]\n",
      "  ...\n",
      "  [-1.3067522   0.9277274  -0.31604427 ...  0.95154685 -0.80097353\n",
      "    1.1197798 ]\n",
      "  [-1.2226936   0.912236   -0.27066547 ...  0.95714116 -0.8456594\n",
      "    1.1905572 ]\n",
      "  [-1.2034514   0.7583094  -0.08467613 ...  0.99823517 -0.85376656\n",
      "    1.1846343 ]]\n",
      "\n",
      " [[-1.4368329   0.98610824 -0.1516133  ...  0.74032116 -0.51190776\n",
      "    1.165991  ]\n",
      "  [-1.4362371   0.9310296   0.02392673 ...  0.77642345 -0.6093266\n",
      "    1.12596   ]\n",
      "  [-1.483105    0.79189837  0.10071998 ...  0.80502295 -0.6529176\n",
      "    1.0844316 ]\n",
      "  ...\n",
      "  [-1.3019228   1.0201135  -0.3085114  ...  0.840699   -0.76794684\n",
      "    1.1446123 ]\n",
      "  [-1.2115855   1.013378   -0.2615724  ...  0.8342138  -0.8087721\n",
      "    1.2218215 ]\n",
      "  [-1.1794511   0.86949503 -0.08143192 ...  0.8859338  -0.8145411\n",
      "    1.2247454 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-1.5385439   1.0127716  -0.18618028 ...  0.7724781  -0.676397\n",
      "    1.1222359 ]\n",
      "  [-1.5319045   0.9551748  -0.02137268 ...  0.8088734  -0.77731633\n",
      "    1.078095  ]\n",
      "  [-1.5755819   0.8073082   0.06137042 ...  0.83611155 -0.8200599\n",
      "    1.0448624 ]\n",
      "  ...\n",
      "  [-1.3711194   1.0482382  -0.32330883 ...  0.86992854 -0.914637\n",
      "    1.1137929 ]\n",
      "  [-1.2893753   1.0361301  -0.28317422 ...  0.8674647  -0.96248513\n",
      "    1.1822007 ]\n",
      "  [-1.2727473   0.8863767  -0.10281927 ...  0.9105639  -0.976387\n",
      "    1.1722816 ]]\n",
      "\n",
      " [[-1.4209768   0.99754125 -0.08882374 ...  0.86281776 -0.59690994\n",
      "    1.1883314 ]\n",
      "  [-1.4111899   0.94169694  0.07050352 ...  0.89902216 -0.70121133\n",
      "    1.142764  ]\n",
      "  [-1.4557241   0.792734    0.14458238 ...  0.92898065 -0.7443287\n",
      "    1.1031028 ]\n",
      "  ...\n",
      "  [-1.2635823   1.0358473  -0.2786762  ...  0.94445914 -0.8286056\n",
      "    1.1622229 ]\n",
      "  [-1.1724011   1.0074068  -0.22289181 ...  0.95406264 -0.87764186\n",
      "    1.2420456 ]\n",
      "  [-1.1564697   0.8622404  -0.02951536 ...  1.0034764  -0.8929529\n",
      "    1.227729  ]]\n",
      "\n",
      " [[-1.5310348   0.9266429  -0.18224393 ...  0.7562759  -0.6046332\n",
      "    1.148028  ]\n",
      "  [-1.538929    0.8682452  -0.01080989 ...  0.79342055 -0.69465476\n",
      "    1.1077003 ]\n",
      "  [-1.6020925   0.7049174   0.08649573 ...  0.8191092  -0.72346026\n",
      "    1.0595361 ]\n",
      "  ...\n",
      "  [-1.3832731   0.9535046  -0.3512279  ...  0.8579712  -0.8278121\n",
      "    1.1381719 ]\n",
      "  [-1.2832305   0.93389326 -0.30585796 ...  0.86698115 -0.86900765\n",
      "    1.2186394 ]\n",
      "  [-1.252947    0.7854223  -0.11569214 ...  0.9107624  -0.8833352\n",
      "    1.2226174 ]]], shape=(64, 40, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# TEST THE CODE\n",
    "if __name__==\"__main__\":\n",
    "\n",
    "    # Hyperparameters\n",
    "    h = 8                  # Number of heads\n",
    "    d_k = 64               # Dimension of the key and query vectors\n",
    "    d_v = 64               # Dimension of the value vectors\n",
    "    d_ff = 2048            # Dimension of the feed-forward layer\n",
    "    d_model = 512          # Dimension of the model sub-layer' output\n",
    "    n = 6                  # Number of encoder layers\n",
    "    batch_size = 64        # Batch size\n",
    "    dropout_rate = 0.1     # Dropout rate\n",
    "    dec_vocab_size = 8000  # Decoder vocabulary size\n",
    "    input_seq_length = 40  # Input sequence length\n",
    "\n",
    "    # Sample dataset\n",
    "    input_seq = np.random.random((batch_size, input_seq_length))\n",
    "    encoder_output = np.random.random((batch_size, input_seq_length, d_model))\n",
    "    \n",
    "    # Feed to the decoder\n",
    "    decoder = Decoder(dec_vocab_size, input_seq_length, h, d_k, d_v, d_model, d_ff, n, dropout_rate)\n",
    "    output_target = decoder(input_seq, encoder_output, None, True)\n",
    "\n",
    "    # Model summary\n",
    "    decoder_layer = DecoderLayer(input_seq_length, h, d_k, d_v, d_model, d_ff, dropout_rate)\n",
    "    \n",
    "    # Print\n",
    "    print(\"Model summary: \", decoder_layer.build_graph().summary())\n",
    "    print(\"Decoder Output: \", output_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### TRANSFORMER\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom class for transformer mode\n",
    "class TransformerModel(tf.keras.Model):\n",
    "\n",
    "    # Constructor function\n",
    "    def __init__(self, enc_vocab_size, dec_vocab_size, enc_seq_length, dec_seq_length, h, d_k, d_v, d_model, d_ff_inner, n, rate, **kwargs):\n",
    "\n",
    "        # Inherite the parent's constructor\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Encoder model\n",
    "        self.encoder = Encoder(enc_vocab_size, enc_seq_length, h, d_k, d_v, d_model, d_ff_inner, n, rate)\n",
    "\n",
    "        # Decoder model\n",
    "        self.decoder = Decoder(dec_vocab_size, dec_seq_length, h, d_k, d_v, d_model, d_ff_inner, n, rate)\n",
    "\n",
    "        # Dense layer\n",
    "        self.last_layer = tf.keras.layers.Dense(dec_vocab_size)\n",
    "\n",
    "    # Function for masking the padding\n",
    "    def padding_mask(self, inputs):\n",
    "\n",
    "        # Create mask (i.e. marks zero paddings by a 1 and 0 elsewhere)\n",
    "        mask = tf.math.equal(inputs, 0)\n",
    "        mask = tf.cast(mask, tf.float32)\n",
    "\n",
    "        # Make the shape broadcastable for the attention weights\n",
    "        mask = mask[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "        return mask\n",
    "    \n",
    "    # Function for masking the lookahead\n",
    "    def lookahead_mask(self, shape):\n",
    "\n",
    "        # Create mask (i.e. marks future words by a 1 and 0 elsewhere)\n",
    "        mask = 1 - tf.linalg.band_part(tf.ones((shape, shape)), -1, 0)\n",
    "\n",
    "        return mask\n",
    "    \n",
    "    # Function for calling the model\n",
    "    def call(self, encoder_input, decoder_input, training):\n",
    "\n",
    "        # Mask the paddings for input data \n",
    "        enc_padding_mask = self.padding_mask(encoder_input)\n",
    "        dec_in_padding_mask = self.padding_mask(decoder_input)\n",
    "\n",
    "        # Mask the lookahead\n",
    "        dec_in_lookahead_mask = self.lookahead_mask(decoder_input.shape[1])\n",
    "        dec_in_lookahead_mask = tf.maximum(dec_in_padding_mask, dec_in_lookahead_mask)\n",
    "\n",
    "        # Feed to encoder\n",
    "        encoder_output = self.encoder(encoder_input, enc_padding_mask, training)\n",
    "\n",
    "        # Feed to decoder\n",
    "        decoder_output = self.decoder(decoder_input, encoder_output, dec_in_lookahead_mask, enc_padding_mask, training)\n",
    "\n",
    "        # Feed to the last layer\n",
    "        model_output = self.last_layer(decoder_output)\n",
    "\n",
    "\n",
    "\n",
    "        return model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.TransformerModel object at 0x7fbe430f8be0>\n"
     ]
    }
   ],
   "source": [
    "# TEST THE CODE\n",
    "if __name__==\"__main__\":\n",
    "\n",
    "    # Hyperparaneters\n",
    "    enc_vocab_size = 20   # Vocabulary size for the encoder\n",
    "    dec_vocab_size = 20   # Vocabulary size for the decoder\n",
    "    enc_seq_length = 5    # Maximum length of the input sequence\n",
    "    dec_seq_length = 5    # Maximum length of the target sequence\n",
    "    h = 8                 # Number of self-attention heads\n",
    "    d_k = 64              # Dimensionality of the linearly projected queries and keys\n",
    "    d_v = 64              # Dimensionality of the linearly projected values\n",
    "    d_ff = 2048           # Dimensionality of the inner fully connected layer\n",
    "    d_model = 512         # Dimensionality of the model sub-layers' outputs\n",
    "    n = 6                 # Number of layers in the encoder stack\n",
    "    dropout_rate = 0.1    # Frequency of dropping the input units in the dropout layers\n",
    "\n",
    "    # Create model\n",
    "    training_model = TransformerModel(enc_vocab_size, dec_vocab_size, enc_seq_length, dec_seq_length, h, d_k, d_v, d_model, d_ff, n, dropout_rate)\n",
    "\n",
    "    print(training_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### TRAINING\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for scheduling the learning ear\n",
    "class LearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    \"\"\"\n",
    "    This class schedules the learning rate.\n",
    "\n",
    "    PARAMETERS\n",
    "    ==========================\n",
    "        - d_model (int): the model's dimensionality\n",
    "        - warmup_steps (int): the number of warmup steps\n",
    "        \n",
    "    RETURNS\n",
    "    ==========================\n",
    "        - learning_rate (tf.Tensor): the learning rate\n",
    "    \"\"\"\n",
    "    \n",
    "    # Constructor function\n",
    "    def __init__(self, d_model, warmup_steps=4_000, **kwargs):\n",
    "\n",
    "        # Inherite the parent's constructor\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Initializations\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    # Call function\n",
    "    def __call__(self, step_num):\n",
    "\n",
    "        # Cast step_num to float\n",
    "        step_num = tf.cast(step_num, tf.float32)\n",
    "\n",
    "        # Linearly increase the learning rate for the first warmup_steps times, then decrease it\n",
    "        arg1 = step_num ** -0.5\n",
    "        arg2 = step_num * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        # Learning rate\n",
    "        learning_rate = (self.d_model ** -0.5) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "        return learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the optimizer with the learning rate scheduler\n",
    "optimizer = tf.keras.optimizers.Adam(LearningRateScheduler(d_model), beta_1, beta_2, epsilon)\n",
    "\n",
    "# Prepare the dataset\n",
    "dataset = PrepareDataset()\n",
    "train_x, train_y, val_x, val_y, train, val, encoder_sequence_length, decoder_sequence_length, encoder_vocabulary_size, decoder_vocabulary_size = dataset(\"./implementations from scratch/dataset/english-german-both.pkl\")\n",
    "\n",
    "# Convert to tf.data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_x, val_y))\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "\n",
    "# Instantiate the model\n",
    "model = TransformerModel(encoder_vocabulary_size, decoder_vocabulary_size, encoder_sequence_length, decoder_sequence_length, h, d_k, d_v, d_model, d_ff, n, dropout_rate)\n",
    "\n",
    "# Include the metrics monitoring\n",
    "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
    "train_accuracy = tf.keras.metrics.Mean(name=\"train_accuracy\")\n",
    "val_loss = tf.keras.metrics.Mean(name=\"val_loss\")\n",
    "\n",
    "# Checkpoint object and manager (for managing multiple checkpoints)\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)\n",
    "checkpoint_manager = tf.train.CheckpointManager(checkpoint, \"./checkpoints\", max_to_keep=None)\n",
    "\n",
    "# Initialize lists for stroing the losses\n",
    "train_loss_d = {}\n",
    "val_loss_d = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for calculating the loss\n",
    "def loss_function(target, prediction):\n",
    "    \"\"\"\n",
    "    This function calculates the loss between the target and the prediction.\n",
    "\n",
    "    PARAMETERS\n",
    "    ==========================\n",
    "        - target (tf.Tensor): the target tensor\n",
    "        - prediction (tf.Tensor): the prediction tensor\n",
    "\n",
    "    RETURNS\n",
    "    ==========================\n",
    "        - loss (tf.Tensor): the loss between the target and the prediction\n",
    "    \"\"\"\n",
    "\n",
    "    # Mask the padding values\n",
    "    mask = tf.math.logical_not(tf.math.equal(target, 0))\n",
    "    mask = tf.cast(mask, tf.float32)\n",
    "\n",
    "    # Computer the sparse categorical cross entropy loss on the unmasked values\n",
    "    loss = tf.keras.losses.sparse_categorical_crossentropy(target, prediction, from_logits=True) * mask\n",
    "\n",
    "    # Calculate the mean loss over the unmasked values\n",
    "    loss = tf.reduce_sum(loss) / tf.reduce_sum(mask)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for calculating the accuracy\n",
    "def accuracy_function(target, prediction):\n",
    "    \"\"\"\n",
    "    Function for calculating the accuracy between the target and the prediction.\n",
    "\n",
    "    PARAMETERS\n",
    "    ==========================\n",
    "        - target (tf.Tensor): the target tensor\n",
    "        - prediction (tf.Tensor): the prediction tensor\n",
    "\n",
    "    RETURNS\n",
    "    ==========================\n",
    "        - out (tf.Tensor): the accuracy between the target and the prediction\n",
    "    \"\"\"\n",
    "\n",
    "    # Mask the padding values\n",
    "    mask = tf.math.logical_not(tf.math.equal(target, 0))\n",
    "    \n",
    "    # Calculate accuracy and apply the padding mask\n",
    "    accuracy = tf.equal(target, tf.argmax(prediction, axis=2))\n",
    "    accuracy = tf.math.logical_and(mask, accuracy)\n",
    "\n",
    "    # Cast the accuracy from boolean to float32\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    accuracy = tf.cast(accuracy, dtype=tf.float32)\n",
    "\n",
    "    # Calculate the mean accuracy over the unmasked values\n",
    "    out = tf.reduce_sum(accuracy) / tf.reduce_sum(mask)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for the training step (to spped up the training process)\n",
    "@tf.function\n",
    "def train_step(encoder_input, decoder_input, decoder_output):\n",
    "    \"\"\"\n",
    "    This function performs a training step.\n",
    "\n",
    "    PARAMETERS\n",
    "    ==========================\n",
    "        - encoder_input (tf.Tensor): the encoder input\n",
    "        - decoder_input (tf.Tensor): the decoder input\n",
    "        - decoder_output (tf.Tensor): the decoder output\n",
    "\n",
    "    RETURNS\n",
    "    ==========================\n",
    "        - None\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the gradient tape\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        # Forward pass (to make predictions)\n",
    "        prediction = model(encoder_input, decoder_input, training=True)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = loss_function(decoder_output, prediction)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = accuracy_function(decoder_output, prediction)\n",
    "\n",
    "    # Fetch the gradients of the trainable variables with respect to the training loss\n",
    "    gradients = tape.gradient(loss, model.trainable_weights)\n",
    "\n",
    "    # Apply the gradients to the optimizer so it can update the model accordingly\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "    # Update the metrics\n",
    "    train_loss(loss)\n",
    "    train_accuracy(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Loop over the epochs\n",
    "for i_epoch in range(epochs):\n",
    "\n",
    "    # Reset the metrics\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    val_loss.reset_states()\n",
    "\n",
    "    # Report \n",
    "    print(f\"Epoch {i_epoch + 1}/{epochs}\" + \"\\n===========================================\")\n",
    "\n",
    "    # Start a timer\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Loop over the training batches\n",
    "    for i_step, (train_batch_x, train_batch_y) in enumerate(train_dataset):\n",
    "\n",
    "        # Define the encoder/decoder input/output\n",
    "        encoder_input = train_batch_x[:, 1:]\n",
    "        decoder_input = train_batch_y[:, :-1]\n",
    "        decoder_output = train_batch_y[:, 1:]\n",
    "\n",
    "        # Perform one training step\n",
    "        train_step(encoder_input, decoder_input, decoder_output)\n",
    "\n",
    "        # Report\n",
    "        if (i_step % 50 == 0):\n",
    "            print(f\"Step {i_step}, Loss = {train_loss.result():.4f}, Accuracy = {train_accuracy.result():.4f}\")\n",
    "\n",
    "    # Loop over the validation batches\n",
    "    for i_step, (val_batch_x, val_batch_y) in enumerate(val_dataset):\n",
    "\n",
    "        # Define the encoder/decoder input/output\n",
    "        encoder_input = val_batch_x[:, 1:]\n",
    "        decoder_input = val_batch_y[:, :-1]\n",
    "        decoder_output = val_batch_y[:, 1:]\n",
    "\n",
    "        # Forward pass (to make predictions)\n",
    "        prediction = model(encoder_input, decoder_input, training=False)\n",
    "\n",
    "        # Calculate the loass\n",
    "        loss = loss_function(decoder_output, prediction)\n",
    "\n",
    "        # Update the metrics\n",
    "        val_loss(loss)\n",
    "\n",
    "        # Reoirt\n",
    "        if (i_step % 50 == 0):\n",
    "            print(f\"Step {i_step}, Validation Loss = {val_loss.result():.4f}\")\n",
    "\n",
    "\n",
    "    # Report\n",
    "    print(f\"Training Loss = {train_loss.result():.4f}, Training Accuracy = {train_accuracy.result():.4f}, Validation Loss = {val_loss.result():.4f}\")\n",
    "\n",
    "    # Save the checkpoint after each epoch\n",
    "    if (i_epoch+1) % 1 == 0:\n",
    "\n",
    "        # Save the checkpoint\n",
    "        save_path = checkpoint_manager.save()\n",
    "\n",
    "        # Report\n",
    "        print(f\"Checkpoint saved at {save_path}.\")\n",
    "\n",
    "        # Save the weights\n",
    "        model.save_weights(\"weights/wghts\" + str(i_epoch + 1) + \".ckpt\")\n",
    "\n",
    "        # Report\n",
    "        train_loss_d[i_epoch] = train_loss.result()\n",
    "        val_loss_d[i_epoch] = val_loss.result()\n",
    "\n",
    "# Save the loss values\n",
    "with open(\"./train_loss.pkl\", \"wb\") as file:  pickle.dump(train_loss_d, file)\n",
    "with open(\"./val_loss.pkl\", \"wb\") as file:  pickle.dump(val_loss_d, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "#    VISUALIZATION    #\n",
    "#######################\n",
    "\n",
    "# Load the training and validation loss dictionaries\n",
    "train_loss = pickle.load(open('train_loss.pkl', 'rb'))\n",
    "val_loss = pickle.load(open('val_loss.pkl', 'rb'))\n",
    "\n",
    "# Retrieve each dictionary's values\n",
    "train_values = train_loss.values()\n",
    "val_values = val_loss.values()\n",
    "\n",
    "# Generate a sequence of integers to represent the epoch numbers\n",
    "epochs = range(1, 21)\n",
    "\n",
    "# Plot and label the training and validation loss values\n",
    "plt.plot(epochs, train_values, label='Training Loss')\n",
    "plt.plot(epochs, val_values, label='Validation Loss')\n",
    "\n",
    "# Add in a title and axes labels\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "# Set the tick locations\n",
    "plt.xticks(np.arange(0, 21, 2))\n",
    "\n",
    "# Display the plot\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### INFERENCE\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom class for inference\n",
    "class Inference(tf.Module):\n",
    "\n",
    "    # Constructor function\n",
    "    def __init__(self, inferencing_model, **kwargs):\n",
    "        \n",
    "        # Inherite the parent's constructor\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Initialize the model\n",
    "        self.transformer = inferencing_model\n",
    "\n",
    "    # Function for loading the tokenizer\n",
    "    def load_tokenizer(self, name):\n",
    "\n",
    "        # Load the tokenizer from the specified file\n",
    "        with open(name, 'rb') as handle: return pickle.load(handle)\n",
    "\n",
    "    # Call function\n",
    "    def __call__(self, sentence):\n",
    "\n",
    "        # Append START and EOS tokens to the input sentence\n",
    "        sentence[0] = \"<START> \" + sentence[0] + \" <EOS>\"\n",
    "\n",
    "        # Load tokenizers for encoder and decoder\n",
    "        enc_tokenizer = self.load_tokenizer('enc_tokenizer.pkl')\n",
    "        dec_tokenizer = self.load_tokenizer('dec_tokenizer.pkl')\n",
    "\n",
    "        # Encoder input; tokenizing, padding and converting to tensor\n",
    "        encoder_input = enc_tokenizer.texts_to_sequences(sentence)\n",
    "        encoder_input = tf.keras.preprocessing.sequence.pad_sequences(encoder_input, maxlen=enc_seq_length, padding='post')\n",
    "        encoder_input = tf.convert_to_tensor(encoder_input, dtype=tf.int64)\n",
    "\n",
    "        # Start of the output sequence is with the <START> token\n",
    "        output_start = dec_tokenizer.texts_to_sequences([\"<START>\"])            # Convert to integers\n",
    "        output_start = tf.convert_to_tensor(output_start[0], dtype=tf.int64)    # Convert to tensor\n",
    "\n",
    "        # End of the output sequence is with the <EOS> token (for breaking the loop)\n",
    "        output_end = dec_tokenizer.texts_to_sequences([\"<EOS>\"])               # Convert to integers\n",
    "        output_end = tf.convert_to_tensor(output_end[0], dtype=tf.int64)      # Convert to tensor\n",
    "\n",
    "        # Output array for storing the predicted tokens (with dynamic size)\n",
    "        decoder_output = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
    "        decoder_output = decoder_output.write(0, output_start)\n",
    "\n",
    "        # Loop over the decoder sequence length\n",
    "        for i in range(dec_seq_length):\n",
    "\n",
    "            # Prediction\n",
    "            prediction = self.transformer(encoder_input,tf. transpose(decoder_output.stack()), training=False)\n",
    "            \n",
    "            # Select the last predicted token\n",
    "            prediction = prediction[:, -1, :]\n",
    "\n",
    "            # Select the prediction with the highest score\n",
    "            predicted_id = tf.argmax(prediction, axis=-1)\n",
    "            predicted_id = predicted_id[0][tf.newaxis]\n",
    "\n",
    "            # Write the selected prediction to the output array at the next available index\n",
    "            decoder_output = decoder_output.write(i + 1, predicted_id)\n",
    "\n",
    "            # Break if an <EOS> token is predicted\n",
    "            if predicted_id == output_end: break\n",
    "\n",
    "        # Transpose the output array and convert to numpy array\n",
    "        output = tf.transpose(decoder_output.stack())[0]\n",
    "        output = output.numpy()\n",
    "\n",
    "        # Initialize an empty list for storing the output string\n",
    "        output_str = []\n",
    "\n",
    "        ### Decode the predicted tokens into an output string\n",
    "\n",
    "        # Loop over the output array\n",
    "        for i in range(output.shape[0]):\n",
    "\n",
    "            # Select the token at the current index\n",
    "            key = output[i]\n",
    "\n",
    "            # Append the token to the output string\n",
    "            output_str.append(dec_tokenizer.index_word[key])\n",
    "\n",
    "        return output_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST THE CODE\n",
    "if __name__==\"__main\":\n",
    "\n",
    "    # Dataset parameters\n",
    "    enc_seq_length = 7      # Encoder sequence length\n",
    "    dec_seq_length = 9      # Decoder sequence length\n",
    "    enc_vocab_size = 786    # Encoder vocabulary size\n",
    "    dec_vocab_size = 1031   # Decoder vocabulary size\n",
    "\n",
    "    # Sample dataset    \n",
    "    sentence = ['im thirsty']                                  # Sentence to translate\n",
    "    \n",
    "    # Initialize the model\n",
    "    inferencing_model = TransformerModel(enc_vocab_size, dec_vocab_size, enc_seq_length, dec_seq_length, h, d_k, d_v, d_model, d_ff, n, 0)\n",
    "\n",
    "    # Load the weights \n",
    "    inferencing_model.load_weights('weights/wghts5.ckpt')      # Load the trained model's weights at the specified epoch\n",
    "    \n",
    "    # Inference\n",
    "    translator = Inference(inferencing_model)                  # Create a new instance of the 'Translate' class\n",
    "    translation = translator(sentence)\n",
    "    \n",
    "    # Report\n",
    "    print(\"Translation: \", translation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "predator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
