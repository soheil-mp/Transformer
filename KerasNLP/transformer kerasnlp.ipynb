{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "<h1 style=\"text-align:center;\">Transformers</h1>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "### INITIAL SETUP\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Turn off the tensorflow logging messages\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qgYgthkCzQBu"
      },
      "outputs": [],
      "source": [
        "# Import the libraries\n",
        "import keras_nlp, os, pathlib, random, warnings\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow_text.tools.wordpiece_vocab import (\n",
        "    bert_vocab_from_dataset as bert_vocab,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Turn off the warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KjCs6rDNzQBv"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 1\n",
        "MAX_SEQUENCE_LENGTH = 60\n",
        "ENG_VOCAB_SIZE = 30000\n",
        "SPA_VOCAB_SIZE = 30000\n",
        "EMBED_DIM = 512\n",
        "INTERMEDIATE_DIM = 2048\n",
        "NUM_HEADS = 8\n",
        "N_ENCODER = 2   # Number of encoders\n",
        "N_DECODER = 2     # Number of encoders\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "### DATASET\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pvMqmWfIzQBv"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PosixPath('/home/soheil/.keras/datasets/spa-eng/spa.txt')"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Download the file\n",
        "text_file = keras.utils.get_file(\n",
        "    fname=\"spa-eng.zip\",\n",
        "    origin=\"http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\",\n",
        "    extract=True,\n",
        ")\n",
        "\n",
        "# Get the path to the spa-eng.txt file\n",
        "text_file = pathlib.Path(text_file).parent / \"spa-eng\" / \"spa.txt\"\n",
        "text_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7BZfRn8VzQBw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(\"my alarm clock didn't work. that's why i was late.\", 'mi reloj despertador no funcionó. es por eso que llegué tarde.')\n",
            "(\"i can't stand being cooped up in this prison!\", '¡no puedo soportar estar encerrado en esta prisión!')\n",
            "('he was somehow able to swim across the river.', 'de alguna manera él fue capaz de nadar hasta el otro lado del río.')\n",
            "('i did that which she asked me to do.', 'hice lo que ella me pidió.')\n",
            "(\"everyone's talking about what tom did.\", 'todo el mundo está hablando de lo que hizo tom.')\n"
          ]
        }
      ],
      "source": [
        "# Load the file\n",
        "with open(text_file) as f: lines = f.read().split(\"\\n\")[:-1]\n",
        "\n",
        "# Initialize the list of text pairs\n",
        "text_pairs = []\n",
        "\n",
        "# Loop over the lines\n",
        "for line in lines:\n",
        "\n",
        "    # Split the line into english and spanish\n",
        "    eng, spa = line.split(\"\\t\")\n",
        "\n",
        "    # Lowercase the text\n",
        "    eng, spa = eng.lower(), spa.lower()\n",
        "\n",
        "    # Append the text pairs\n",
        "    text_pairs.append((eng, spa))\n",
        "\n",
        "# Randomly print text pairs\n",
        "for _ in range(5):   print(random.choice(text_pairs))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "### DATA PREPROCESSING\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "spuBrwrRzQBw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "118964 total pairs\n",
            "83276 training pairs\n",
            "17844 validation pairs\n",
            "17844 test pairs\n"
          ]
        }
      ],
      "source": [
        "# Function for splitting the text pAairs into training, validation and test samples\n",
        "def split_text_pairs(text_pairs):\n",
        "    \"\"\"\n",
        "    This function splits the text pairs into training, validation and test samples.\n",
        "\n",
        "    ARGUMENTS\n",
        "    ======================\n",
        "        - text_pairs (list): List of text pairs\n",
        "\n",
        "    RETURNS\n",
        "    ======================\n",
        "        - train_pairs (list): List of training text pairs\n",
        "        - val_pairs (list): List of validation text pairs\n",
        "        - test_pairs (list): List of test text pairs\n",
        "    \"\"\"\n",
        "\n",
        "    # Shuffle the text pairs\n",
        "    random.shuffle(text_pairs)\n",
        "\n",
        "    # Number of training, validation and test samples\n",
        "    num_val_samples = int(0.15 * len(text_pairs))\n",
        "    num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
        "\n",
        "    # Split the text pairs into training, validation and test samples\n",
        "    train_pairs = text_pairs[:num_train_samples]\n",
        "    val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n",
        "    test_pairs = text_pairs[num_train_samples + num_val_samples :]\n",
        "    \n",
        "    return train_pairs, val_pairs, test_pairs\n",
        "\n",
        "\n",
        "# Create a function to tokenize the text\n",
        "def train_word_piece(text_samples, vocab_size):\n",
        "    \"\"\"\n",
        "    This function tokenizes the text samples using the word piece tokenizer.\n",
        "\n",
        "    ARGUMENTS\n",
        "    =================\n",
        "        - text_samples (list): A list of text samples.\n",
        "        - vocab_size (int): The size of the vocabulary.\n",
        "        - reserved_tokens (list): A list of reserved tokens.\n",
        "\n",
        "    RETURNS\n",
        "    =================\n",
        "        - vocab (tf.Tensor): A tensor containing the vocabulary.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize the reserved tokens\n",
        "    reserved_tokens = [\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\"]\n",
        "\n",
        "    # Create a TensorFlow dataset\n",
        "    word_piece_ds = tf.data.Dataset.from_tensor_slices(text_samples)\n",
        "\n",
        "    # Create a vocabulary\n",
        "    vocab = keras_nlp.tokenizers.compute_word_piece_vocabulary(word_piece_ds.batch(1000).prefetch(2),\n",
        "                                                               vocabulary_size=vocab_size,\n",
        "                                                               reserved_tokens=reserved_tokens,)\n",
        "    \n",
        "    return vocab\n",
        "\n",
        "\n",
        "# Function for preprocessing a batch of text pairs\n",
        "def preprocess_batch(eng, spa):\n",
        "    \"\"\"\n",
        "    This function preprocesses a batch of text pairs.\n",
        "\n",
        "    ARGUMENTS\n",
        "    ======================\n",
        "        - eng (tf.Tensor): A tensor containing the english text.\n",
        "        - spa (tf.Tensor): A tensor containing the spanish text.\n",
        "\n",
        "    RETURNS\n",
        "    ======================\n",
        "        - inputs (dict): A dictionary containing the encoder input (english text) and decoder input (spanish text except the last token).\n",
        "        - outputs (tf.Tensor): A tensor containing the decoder output (spanish text except the first token).\n",
        "    \"\"\"\n",
        "\n",
        "    # Batch size\n",
        "    batch_size = tf.shape(spa)[0]\n",
        "\n",
        "    # Tokenize the english and spanish text\n",
        "    eng = eng_tokenizer(eng)\n",
        "    spa = spa_tokenizer(spa)\n",
        "\n",
        "    # Pad the english text to the maximum sequence length\n",
        "    eng_start_end_packer = keras_nlp.layers.StartEndPacker(\n",
        "        sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "        pad_value=eng_tokenizer.token_to_id(\"[PAD]\"),\n",
        "    )\n",
        "\n",
        "    # Apply to the english text\n",
        "    eng = eng_start_end_packer(eng)\n",
        "\n",
        "    # Initialize a custom layer for adding start, end, and padding token\n",
        "    spa_start_end_packer = keras_nlp.layers.StartEndPacker(sequence_length=MAX_SEQUENCE_LENGTH + 1,\n",
        "                                                           start_value=spa_tokenizer.token_to_id(\"[START]\"),\n",
        "                                                           end_value=spa_tokenizer.token_to_id(\"[END]\"),\n",
        "                                                           pad_value=spa_tokenizer.token_to_id(\"[PAD]\") )\n",
        "    \n",
        "    # Apply to the spanish text\n",
        "    spa = spa_start_end_packer(spa)\n",
        "\n",
        "    # Get the inputs and outputs\n",
        "    inputs = {\"encoder_inputs\": eng, \"decoder_inputs\": spa[:, :-1]}     # Encoder input (i.e. english text) and decoder input (i.e. spanish text except the last token)\n",
        "    outputs = spa[:, 1:]                                                # Decoder output (i.e. spanish text except the first token) \n",
        "\n",
        "    return (inputs, outputs)\n",
        "\n",
        "\n",
        "# Create a function to make a dataset\n",
        "def make_dataset(pairs):\n",
        "    \"\"\"\n",
        "    This function creates a TensorFlow dataset.\n",
        "\n",
        "    ARGUMENTS\n",
        "    ======================\n",
        "        - pairs (list): A list of text pairs.\n",
        "\n",
        "    RETURNS\n",
        "    ======================\n",
        "        - dataset (tf.data.Dataset): A TensorFlow dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    # Zip the english and spanish text together\n",
        "    eng_texts, spa_texts = zip(*pairs)\n",
        "\n",
        "    # Convert into list\n",
        "    eng_texts, spa_texts = list(eng_texts), list(spa_texts)\n",
        "\n",
        "    # Convert into TensorFlow dataset\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
        "    \n",
        "    # Set the batch size\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    \n",
        "    # Preprocess the batch (in parallel)\n",
        "    dataset = dataset.map(preprocess_batch, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    # Shuffle, prefetch and cache the dataset\n",
        "    dataset = dataset.shuffle(2048).prefetch(16).cache()\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KAOk3EozQBx"
      },
      "outputs": [],
      "source": [
        "# Split the text pairs into training, validation and test samples\n",
        "train_pairs, val_pairs, test_pairs = split_text_pairs(text_pairs)\n",
        "\n",
        "# Print the number of samples\n",
        "print(f\"{len(text_pairs)} total pairs\")\n",
        "print(f\"{len(train_pairs)} training pairs\")\n",
        "print(f\"{len(val_pairs)} validation pairs\")\n",
        "print(f\"{len(test_pairs)} test pairs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "English Tokens:  ['at', 'know', 'him', 'there', 'they', 'go', 'her', 'has', 'will', 're']\n",
            "Spanish Tokens:  ['con', 'mi', 'qué', 'ella', 'le', 'te', 'para', 'mary', 'las', 'más']\n"
          ]
        }
      ],
      "source": [
        "# Get the english and spanish texts from the text pairs\n",
        "eng_samples = [text_pair[0] for text_pair in train_pairs]\n",
        "spa_samples = [text_pair[1] for text_pair in train_pairs]\n",
        "\n",
        "# Get the english and spanish vocabularies\n",
        "eng_vocab = train_word_piece(eng_samples, ENG_VOCAB_SIZE)\n",
        "spa_vocab = train_word_piece(spa_samples, SPA_VOCAB_SIZE)\n",
        "\n",
        "# Print sample english and spanish tokens\n",
        "print(\"English Tokens: \", eng_vocab[100:110])\n",
        "print(\"Spanish Tokens: \", spa_vocab[100:110])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_JbWCkQDzQBx"
      },
      "outputs": [],
      "source": [
        "# Create the tokenizer for english and spanish words\n",
        "eng_tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(vocabulary=eng_vocab, lowercase=False)\n",
        "spa_tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(vocabulary=spa_vocab, lowercase=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inputs[\"encoder_inputs\"].shape: (64, 60)\n",
            "inputs[\"decoder_inputs\"].shape: (64, 60)\n",
            "targets.shape: (64, 60)\n"
          ]
        }
      ],
      "source": [
        "# Convert the text pairs into a TensorFlow dataset\n",
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)\n",
        "\n",
        "# Print sample dataset\n",
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
        "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
        "    print(f\"targets.shape: {targets.shape}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "### MODEL ARCHITECTURE\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_inputs (InputLayer)  [(None, None)]           0         \n",
            "                                                                 \n",
            " token_and_position_embeddin  (None, None, 512)        15390720  \n",
            " g (TokenAndPositionEmbeddin                                     \n",
            " g)                                                              \n",
            "                                                                 \n",
            " transformer_encoder (Transf  (None, None, 512)        3152384   \n",
            " ormerEncoder)                                                   \n",
            "                                                                 \n",
            " transformer_encoder_1 (Tran  (None, None, 512)        3152384   \n",
            " sformerEncoder)                                                 \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,695,488\n",
            "Trainable params: 21,695,488\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#################\n",
        "#    ENCODER    #\n",
        "#################\n",
        "\n",
        "# Input\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "\n",
        "# Token and Position Embedding\n",
        "x = keras_nlp.layers.TokenAndPositionEmbedding(vocabulary_size=ENG_VOCAB_SIZE,\n",
        "                                               sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "                                               embedding_dim=EMBED_DIM,\n",
        "                                               mask_zero=True)(encoder_inputs)\n",
        "\n",
        "# Transformer Encoder\n",
        "for _ in range(N_ENCODER):\n",
        "    x = keras_nlp.layers.TransformerEncoder(intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS)(inputs=x)\n",
        "\n",
        "# Create the model\n",
        "encoder = keras.Model(encoder_inputs, x, name=\"encoder\")\n",
        "encoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"decoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " token_and_position_embedding_1  (None, None, 512)   15390720    ['decoder_inputs[0][0]']         \n",
            "  (TokenAndPositionEmbedding)                                                                     \n",
            "                                                                                                  \n",
            " decoder_state_inputs (InputLay  [(None, None, 512)]  0          []                               \n",
            " er)                                                                                              \n",
            "                                                                                                  \n",
            " transformer_decoder (Transform  (None, None, 512)   4204032     ['token_and_position_embedding_1[\n",
            " erDecoder)                                                      0][0]',                          \n",
            "                                                                  'decoder_state_inputs[0][0]']   \n",
            "                                                                                                  \n",
            " transformer_decoder_1 (Transfo  (None, None, 512)   4204032     ['transformer_decoder[0][0]',    \n",
            " rmerDecoder)                                                     'decoder_state_inputs[0][0]']   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 30000)  15390000    ['transformer_decoder_1[0][0]']  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 39,188,784\n",
            "Trainable params: 39,188,784\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#################\n",
        "#    DECODER    #\n",
        "#################\n",
        "\n",
        "# Inputs\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "encoded_seq_inputs = keras.Input(shape=(None, EMBED_DIM), name=\"decoder_state_inputs\")\n",
        "\n",
        "# Token and Position Embedding\n",
        "x = keras_nlp.layers.TokenAndPositionEmbedding(vocabulary_size=SPA_VOCAB_SIZE,\n",
        "                                               sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "                                               embedding_dim=EMBED_DIM,\n",
        "                                               mask_zero=True)(decoder_inputs)\n",
        "\n",
        "# Transformer Decoder\n",
        "for _ in range(N_DECODER):\n",
        "    x = keras_nlp.layers.TransformerDecoder(intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS)(decoder_sequence=x, encoder_sequence=encoded_seq_inputs)\n",
        "\n",
        "# Dense layer\n",
        "decoder_outputs = keras.layers.Dense(SPA_VOCAB_SIZE, activation=\"softmax\")(x)\n",
        "\n",
        "# Create the model\n",
        "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs, name=\"decoder\")\n",
        "decoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, None, 512)    21695488    ['encoder_inputs[0][0]']         \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, None, 30000)  39188784    ['decoder_inputs[0][0]',         \n",
            "                                                                  'encoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 60,884,272\n",
            "Trainable params: 60,884,272\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#####################\n",
        "#    TRANSFORMER    #\n",
        "#####################\n",
        "\n",
        "# Get the output of the encoder and decoder\n",
        "encoder_outputs = encoder(encoder_inputs)\n",
        "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
        "\n",
        "# Create the model\n",
        "transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\")\n",
        "transformer.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "### TRAINING\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "transformer.compile(\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the model\n",
        "#transformer.fit(train_ds, epochs=EPOCHS, validation_data=val_ds)\n",
        "# 1302/1302 [==============================] - 169s 120ms/step - loss: 3.5289 - accuracy: 0.4403 - val_loss: 2.5349 - val_accuracy: 0.5534"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1302/1302 [==============================] - 404s 296ms/step - loss: 3.7020 - accuracy: 0.3919 - val_loss: 3.1765 - val_accuracy: 0.4334\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb0107e3190>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the model\n",
        "transformer.fit(train_ds, epochs=EPOCHS, validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the model\n",
        "transformer.save(\"transformer.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, None, 512)    21695488    ['encoder_inputs[0][0]']         \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, None, 30000)  39188784    ['decoder_inputs[0][0]',         \n",
            "                                                                  'encoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 60,884,272\n",
            "Trainable params: 60,884,272\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Load the model\n",
        "transformer = tf.keras.models.load_model(\"transformer.h5\")\n",
        "transformer.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "### PREDICTION\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "zu10YffLzQBz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "** Example 0 **\n",
            "tom is not welcome in this house.\n",
            "tom no es el único que mary .\n",
            "\n",
            "** Example 1 **\n",
            "i don't feel like taking a walk now.\n",
            "no me gusta un paseo .\n",
            "\n",
            "** Example 2 **\n",
            "my brother has joined the baseball club.\n",
            "mi padre tiene tres años .\n",
            "\n",
            "** Example 3 **\n",
            "she argued with him and then hit him.\n",
            "ella se sentó en su casa .\n",
            "\n",
            "** Example 4 **\n",
            "tom bought mary an expensive umbrella.\n",
            "tom se encontró un accidente de su perro .\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def decode_sequences(input_sentences):\n",
        "    batch_size = tf.shape(input_sentences)[0]\n",
        "\n",
        "    # Tokenize the encoder input.\n",
        "    encoder_input_tokens = eng_tokenizer(input_sentences).to_tensor(\n",
        "        shape=(None, MAX_SEQUENCE_LENGTH)\n",
        "    )\n",
        "\n",
        "    # Define a function that outputs the next token's probability given the\n",
        "    # input sequence.\n",
        "    def next(prompt, cache, index):\n",
        "        logits = transformer([encoder_input_tokens, prompt])[:, index - 1, :]\n",
        "        # Ignore hidden states for now; only needed for contrastive search.\n",
        "        hidden_states = None\n",
        "        return logits, hidden_states, cache\n",
        "\n",
        "    # Build a prompt of length 40 with a start token and padding tokens.\n",
        "    length = 40\n",
        "    start = tf.fill((batch_size, 1), spa_tokenizer.token_to_id(\"[START]\"))\n",
        "    pad = tf.fill((batch_size, length - 1), spa_tokenizer.token_to_id(\"[PAD]\"))\n",
        "    prompt = tf.concat((start, pad), axis=-1)\n",
        "\n",
        "    generated_tokens = keras_nlp.samplers.GreedySampler()(\n",
        "        next,\n",
        "        prompt,\n",
        "        end_token_id=spa_tokenizer.token_to_id(\"[END]\"),\n",
        "        index=1,  # Start sampling after start token.\n",
        "    )\n",
        "    generated_sentences = spa_tokenizer.detokenize(generated_tokens)\n",
        "    return generated_sentences\n",
        "\n",
        "\n",
        "test_eng_texts = [pair[0] for pair in test_pairs]\n",
        "for i in range(5):\n",
        "    input_sentence = random.choice(test_eng_texts)\n",
        "    translated = decode_sequences(tf.constant([input_sentence]))\n",
        "    translated = translated.numpy()[0].decode(\"utf-8\")\n",
        "    translated = (\n",
        "        translated.replace(\"[PAD]\", \"\")\n",
        "        .replace(\"[START]\", \"\")\n",
        "        .replace(\"[END]\", \"\")\n",
        "        .strip()\n",
        "    )\n",
        "    print(f\"** Example {i} **\")\n",
        "    print(input_sentence)\n",
        "    print(translated)\n",
        "    print()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<br>\n",
        "\n",
        "### EVALUATION\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "LI9h_80ezQBz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROUGE-1 Score:  {'precision': <tf.Tensor: shape=(), dtype=float32, numpy=0.20665598>, 'recall': <tf.Tensor: shape=(), dtype=float32, numpy=0.19850121>, 'f1_score': <tf.Tensor: shape=(), dtype=float32, numpy=0.19998457>}\n",
            "ROUGE-2 Score:  {'precision': <tf.Tensor: shape=(), dtype=float32, numpy=0.052222226>, 'recall': <tf.Tensor: shape=(), dtype=float32, numpy=0.04666667>, 'f1_score': <tf.Tensor: shape=(), dtype=float32, numpy=0.047683466>}\n"
          ]
        }
      ],
      "source": [
        "rouge_1 = keras_nlp.metrics.RougeN(order=1)\n",
        "rouge_2 = keras_nlp.metrics.RougeN(order=2)\n",
        "\n",
        "for test_pair in test_pairs[:30]:\n",
        "    input_sentence = test_pair[0]\n",
        "    reference_sentence = test_pair[1]\n",
        "\n",
        "    translated_sentence = decode_sequences(tf.constant([input_sentence]))\n",
        "    translated_sentence = translated_sentence.numpy()[0].decode(\"utf-8\")\n",
        "    translated_sentence = (\n",
        "        translated_sentence.replace(\"[PAD]\", \"\")\n",
        "        .replace(\"[START]\", \"\")\n",
        "        .replace(\"[END]\", \"\")\n",
        "        .strip()\n",
        "    )\n",
        "\n",
        "    rouge_1(reference_sentence, translated_sentence)\n",
        "    rouge_2(reference_sentence, translated_sentence)\n",
        "\n",
        "print(\"ROUGE-1 Score: \", rouge_1.result())\n",
        "print(\"ROUGE-2 Score: \", rouge_2.result())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "neural_machine_translation_with_keras_nlp",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
